#+TITLE: Apuntes Sistemas Operativos 
#+Author: Eduardo Alcaraz
#+LANGUAGE: es
#+LaTeX_HEADER: \usepackage[spanish]{inputenc}
#+SETUPFILE: /home/likcos/Materias/SO/theme-readtheorg-local.setup
#+EXPORT_FILE_NAME: index.html
#+OPTIONS: num:nil
#+HTML_HEAD: <style> #content{max-width:1800px;}</style>
#+HTML_HEAD: <style>pre.src {background-color: #303030; color: #e5e5e5;}</style>



* Administración de Procesos y del procesador
** Comandos para manejar procesos en Linux

*** 1. Ver procesos activos
   - `ps`
     Muestra una lista de procesos en la terminal actual. Ofrece información sobre el PID, usuario, CPU, memoria, etc.
     - Ejemplo: `ps aux` muestra todos los procesos en ejecución en el sistema.

   - `top` 
     Muestra una lista dinámica de procesos en tiempo real, actualizándose constantemente. Incluye el uso de CPU, memoria, y estadísticas del sistema.
     - Comando alternativo: `htop`, que ofrece una interfaz más visual y personalizable.

   - `pgrep <nombre>`
     Busca el PID (Process ID) de un proceso específico por su nombre. Útil para obtener el PID antes de aplicar otros comandos.
     - Ejemplo: `pgrep apache` muestra el PID del proceso con el nombre "apache".

*** 2. Iniciar procesos
   - `&` 
     Ejecuta un comando en segundo plano, permitiendo que el usuario continúe usando la terminal. 
     - Ejemplo: `comando &` ejecuta el proceso en segundo plano.

   - `nohup <comando> &`
     Inicia un proceso que continúa en ejecución incluso después de cerrar la terminal. El output se guarda en un archivo `nohup.out` por defecto.
     - Ejemplo: `nohup script.sh &` ejecuta `script.sh` y permanece activo tras cerrar sesión.

*** 3. Controlar la ejecución de procesos
   - `fg` 
     Trae un proceso en segundo plano al primer plano, permitiendo interactuar directamente con él.

   - `bg`
     Envía un proceso suspendido al segundo plano, liberando la terminal para otros comandos.

   - `jobs`
     Muestra los procesos en segundo plano o suspendidos asociados a la sesión de terminal actual, con su ID de trabajo (job ID).

*** 4. Enviar señales a los procesos
   - `kill <PID>` 
     Envía una señal de terminación al proceso especificado por su PID. Intenta cerrar el proceso de manera controlada.
     - Ejemplo: `kill 1234` termina el proceso con PID 1234.

   - `kill -9 <PID>`
     Fuerza el cierre inmediato del proceso especificado, sin esperar una terminación ordenada. Utiliza la señal `KILL`.
     - Ejemplo: `kill -9 1234`.

   - `pkill <nombre>`
     Termina todos los procesos que coinciden con el nombre especificado.
     - Ejemplo: `pkill apache` detiene todos los procesos con nombre "apache".

   - `killall <nombre>`
     Similar a `pkill`, detiene todos los procesos con un nombre específico.
     - Ejemplo: `killall httpd`.

*** 5. Cambiar prioridad de procesos
   - `nice -n <prioridad> <comando>`
     Inicia un proceso con una prioridad especificada, donde el rango va de -20 (mayor prioridad) a 19 (menor prioridad). La prioridad afecta el orden de planificación.
     - Ejemplo: `nice -n -10 script.sh` ejecuta `script.sh` con una prioridad alta.

   - `renice <prioridad> <PID>`
     Cambia la prioridad de un proceso en ejecución.
     - Ejemplo: `renice -5 1234` ajusta la prioridad del proceso con PID 1234.

*** 6. Ver detalles específicos de los procesos
   - `pstree`
     Muestra los procesos en una estructura de árbol, permitiendo visualizar mejor las relaciones y jerarquías entre procesos en ejecución.

   - `lsof -p <PID>`
     Lista todos los archivos abiertos por un proceso específico, útil para ver conexiones de red o archivos utilizados por un proceso.
     - Ejemplo: `lsof -p 1234` muestra los archivos abiertos por el proceso con PID 1234.



** Punteros en C
*** ¿Qué es un puntero?
Un puntero es una variable que almacena la dirección de memoria de
otra variable. En lugar de contener un valor directo, un puntero
"apunta" a la ubicación donde se almacena ese valor.

*** Declaración de punteros
Para declarar un puntero, se utiliza el operador `*` antes del nombre
de la variable:

#+BEGIN_SRC c
int *ptr;
#+END_SRC

En este ejemplo, `ptr` es un puntero a un entero.

*** Inicialización de punteros
Un puntero debe inicializarse con la dirección de una variable antes de ser utilizado. Para obtener la dirección de una variable, se emplea el operador `&`:

#+BEGIN_SRC c
int var = 10;
int *ptr = &var;
#+END_SRC

Aquí, `ptr` almacena la dirección de `var`.

*** Acceso al valor apuntado
Para acceder o modificar el valor de la variable a la que apunta un
puntero, se utiliza el operador de desreferencia `*`:

#+BEGIN_SRC c
printf("Valor de var: %d\n", *ptr); // Imprime: Valor de var: 10
*ptr = 20; // Ahora var vale 20
#+END_SRC

*** Punteros y arreglos
En C, el nombre de un arreglo actúa como un puntero al primer elemento
del mismo. Por lo tanto, se puede utilizar aritmética de punteros para
recorrer un arreglo:

#+BEGIN_SRC c
int arr[3] = {1, 2, 3};
int *ptr = arr;

for (int i = 0; i < 3; i++) {
    printf("%d ", *(ptr + i));
}
// Salida: 1 2 3
#+END_SRC

*** Punteros y funciones
Los punteros permiten que las funciones modifiquen variables fuera de
su ámbito local. Al pasar la dirección de una variable a una función,
esta puede alterar el valor original:

#+BEGIN_SRC C :results output
#include <stdio.h>
void incrementar(int *n) {
    (*n)++;
}
int main() {
    int num = 5;
    incrementar(&num);
    printf("Valor de num: %d\n", num); // Imprime: Valor de num: 6
    return 0;
}
#+END_SRC

#+RESULTS:
: Valor de num: 6

*** Punteros nulos
Un puntero nulo es un puntero que no apunta a ninguna dirección
válida. Se inicializa asignándole el valor `NULL`:

#+BEGIN_SRC c
int *ptr = NULL;
#+END_SRC

Es una buena práctica inicializar los punteros a `NULL` para evitar
errores al intentar acceder a direcciones de memoria no válidas.

*** Aritmética de punteros
Los punteros pueden incrementarse o decrementarse para navegar por
estructuras de datos en memoria:

#+BEGIN_SRC c
int arr[3] = {10, 20, 30};
int *ptr = arr;

ptr++; // Ahora apunta a arr[1]
printf("%d\n", *ptr); // Imprime: 20
#+END_SRC

*** Punteros a punteros
Un puntero puede apuntar a otro puntero, lo que se denomina "puntero a puntero":

#+BEGIN_SRC c
int var = 100;
int *ptr = &var;
int **ptr2 = &ptr;

printf("Valor de var: %d\n", **ptr2); // Imprime: Valor de var: 100
#+END_SRC

*** Dobles y triples punteros
Un **doble puntero** es un puntero que apunta a otro puntero,
permitiendo manejar niveles adicionales de indirección en la
memoria. Estos son útiles en casos como el manejo de matrices
dinámicas o la manipulación de punteros en funciones.

#+BEGIN_SRC c
int var = 50;
int *ptr = &var;
int **dbl_ptr = &ptr;

printf("Valor de var usando dbl_ptr: %d\n", **dbl_ptr); // Imprime: 50
#+END_SRC

Los **triples punteros** (punteros a dobles punteros) permiten gestionar
estructuras de datos de mayor complejidad, como matrices 3D o
estructuras donde necesitas referencias a varios niveles de punteros.

#+BEGIN_SRC c
int var = 30;
int *ptr = &var;
int **dbl_ptr = &ptr;
int ***trp_ptr = &dbl_ptr;

printf("Valor de var usando trp_ptr: %d\n", ***trp_ptr); // Imprime: 30
#+END_SRC

Usar punteros de múltiples niveles requiere tener una buena comprensión de cómo funciona la memoria en C y saber manejar las referencias con cuidado para evitar errores de acceso a memoria.


*** Punteros y cadenas de caracteres
Las cadenas de caracteres en C son arreglos de caracteres terminados en un carácter nulo (`'\0'`). Los punteros se utilizan comúnmente para manipular estas cadenas:

#+BEGIN_SRC c
char str[] = "Hola";
char *ptr = str;

while (*ptr != '\0') {
    printf("%c", *ptr);
    ptr++;
}
// Salida: Hola
#+END_SRC

** Concepto de proceso
Un proceso es una unidad de ejecución dentro de un sistema
operativo. Cada proceso tiene su propio espacio de memoria, que
incluye el código del programa, sus datos y su pila. La creación de un
proceso implica varias operaciones del sistema operativo, como
asignación de memoria y registro en la tabla de procesos. Los procesos
permiten a los sistemas multitarea ejecutar múltiples programas de
forma aparentemente simultánea.

** Fork() en C
*** ¿Qué es fork()?
`fork()` es una llamada al sistema en C, utilizada para crear un nuevo
proceso llamado "proceso hijo". Este proceso es una copia casi exacta
del proceso que hizo la llamada, conocido como "proceso padre". La
función `fork()` es esencial para el manejo de procesos en sistemas
tipo Unix/Linux.

*** Funcionamiento básico de fork()
Cuando se llama a `fork()`, la ejecución continúa tanto en el proceso
padre como en el proceso hijo. La llamada a `fork()` retorna un valor
distinto en cada uno:
- Al proceso **padre**, `fork()` devuelve el PID (identificador de
  proceso) del proceso hijo.
- Al proceso **hijo**, `fork()` devuelve el valor `0`.
- Si ocurre un error, `fork()` retorna `-1`.

*** Ejemplo básico de fork()
A continuación, un ejemplo sencillo que muestra cómo usar `fork()`
para crear un proceso hijo:

#+BEGIN_SRC C :results output
#include <stdio.h>
#include <unistd.h>
int main() {
    pid_t pid = fork(); // Llamada a fork()

    if (pid == -1) {
        // Si ocurre un error en fork()
        perror("fork failed");
        return 1;
    } else if (pid == 0) {
        // Código que ejecuta el proceso hijo
        printf("Este es el proceso hijo con PID: %d\n", getpid());
    } else {
        // Código que ejecuta el proceso padre
        printf("Este es el proceso padre con PID: %d y el hijo tiene PID: %d\n", getpid(), pid);
    }
    return 0;
}
#+END_SRC

#+RESULTS:
: Este es el proceso padre con PID: 194615 y el hijo tiene PID: 194616
: Este es el proceso hijo con PID: 194616

*** Explicación del Ejemplo
1. `fork()` es llamado y crea un proceso hijo.
2. En el proceso hijo, `pid` será igual a `0`, por lo que se ejecutará
   el bloque de código que imprime el mensaje del hijo.
3. En el proceso padre, `pid` es mayor que `0`, por lo que ejecuta el
   código para el proceso padre.
4. Si `fork()` falla, devuelve `-1` y se imprime un mensaje de error.

*** Espera del Proceso Padre con wait()
Para que el proceso padre espere a que el proceso hijo termine antes
de continuar, se puede utilizar la función `wait()`:

#+BEGIN_SRC C :results output 
#include <stdio.h>
#include <unistd.h>
//#include <sys/wait.h>

int main() {
    pid_t pid = fork();

    if (pid == 0) {
        // Proceso hijo
        printf("Proceso hijo con PID: %d\n", getpid());
    } else {
        // Proceso padre
//        wait(NULL); // Espera a que el proceso hijo termine
        printf("Proceso padre con PID: %d, el hijo terminó.\n", getpid());
    }
    return 0;
}
#+END_SRC

#+RESULTS:
: Proceso hijo con PID: 197476
: Proceso padre con PID: 197475, el hijo terminó.

En este ejemplo, el proceso padre esperará hasta que el proceso hijo
termine antes de imprimir su mensaje.

*** fork() y Punteros
`fork()` crea un espacio de memoria independiente para el proceso
hijo, lo que significa que los punteros en el proceso hijo apuntan a
las mismas posiciones relativas que en el proceso padre, pero en
diferentes espacios de memoria. Esto evita que los cambios en las
variables del proceso hijo afecten al padre, gracias al mecanismo de
**Copy-on-Write (COW)**.

*** Ejemplo con Punteros
Este ejemplo demuestra cómo `fork()` maneja los punteros y el espacio de memoria independiente:

#+BEGIN_SRC c
#include <stdio.h>
#include <unistd.h>
#include <stdlib.h>

int main() {
    int *ptr = (int*)malloc(sizeof(int));
    *ptr = 100;

    pid_t pid = fork();

    if (pid == 0) {
        // Proceso hijo
        printf("Proceso hijo: valor de *ptr antes de cambiar = %d\n", *ptr);
        *ptr = 200;
        printf("Proceso hijo: valor de *ptr después de cambiar = %d\n", *ptr);
    } else {
        // Proceso padre
        wait(NULL);
        printf("Proceso padre: valor de *ptr = %d\n", *ptr);
    }

    free(ptr);
    return 0;
}
#+END_SRC

*** Salida esperada
La salida de este código será algo similar a:

: Proceso hijo: valor de *ptr antes de cambiar = 100
: Proceso hijo: valor de *ptr después de cambiar = 200
: Proceso padre: valor de *ptr = 100

*** Explicación de Copy-on-Write (COW)
Gracias a Copy-on-Write, ambos procesos (padre e hijo) comparten la misma memoria hasta que uno de ellos intenta modificarla. En ese momento, el sistema operativo crea una copia independiente de la memoria para el proceso que realiza la escritura, evitando que los cambios afecten al otro proceso.

*** Conclusión
La llamada a `fork()` es una herramienta poderosa en C para la creación de procesos en sistemas operativos Unix/Linux. Permite duplicar un proceso, crear nuevos flujos de ejecución, y manejar recursos compartidos de manera controlada. Es especialmente útil en programas multitarea como servidores o aplicaciones que requieren procesamiento paralelo.

** Estados y transiciones de los procesos
Los procesos en un sistema operativo pueden estar en diferentes
estados, que determinan si están utilizando la CPU, esperando, o
listos para ejecutarse. Los estados comunes incluyen:
  - **Nuevo**: El proceso está siendo creado.
  - **Listo**: El proceso está listo para ejecutarse.
  - **Ejecución**: El proceso está ejecutándose en la CPU.
  - **Bloqueado**: El proceso está esperando un evento externo (por ejemplo, entrada/salida).
  - **Terminado**: El proceso ha completado su ejecución.

Los sistemas operativos gestionan estas transiciones mediante una
estructura de datos llamada tabla de procesos.


*** Ejemplo en C: Creación de un proceso utilizando fork()
#+BEGIN_SRC C :results output
#include <stdio.h>
#include <unistd.h>
#include <sys/types.h>

int main() {
    pid_t pid = fork(); // Crear un nuevo proceso
    if (pid == 0) {
        printf("Soy el proceso hijo con PID %d\n", getpid());
    } else {
        printf("Soy el proceso padre con PID %d\n", getpid());
    }
    return 0;
}
#+END_SRC

#+RESULTS:
: Soy el proceso padre con PID 61713
: Soy el proceso hijo con PID 61714



*** Ejemplo en C: Simulación de transiciones de estados
#+BEGIN_SRC C :results output
#include <stdio.h>
#include <unistd.h>
#include <stdlib.h>
#include <sys/wait.h>

int main() {
    printf("Proceso creado\n");
    pid_t pid = fork();
    if (pid == 0) {
        printf("Estado: Ejecución - Proceso hijo\n");
        sleep(2); // Simula un proceso en espera (bloqueado)
        printf("Estado: Terminado - Proceso hijo\n");
        exit(0);
    } else {
        printf("Estado: Listo - Proceso padre\n");
        wait(NULL); // Espera a que el proceso hijo finalice
        printf("Estado: Terminado - Proceso padre\n");
    }
    return 0;
}
#+END_SRC

#+RESULTS:
: Proceso creado
: Estado: Ejecución - Proceso hijo
: Estado: Terminado - Proceso hijo
: Proceso creado
: Estado: Listo - Proceso padre
: Estado: Terminado - Proceso padre

** Tabla de Procesos
*** ¿Qué es la Tabla de Procesos?
La **Tabla de Procesos** es una estructura de datos utilizada por el
sistema operativo para gestionar todos los procesos activos en el
sistema. Cada proceso tiene un bloque específico, llamado **Bloque de
Control de Proceso (PCB)**, que contiene la información necesaria para
su administración.

*** Información en la Tabla de Procesos
Cada entrada en la tabla de procesos incluye un PCB con varios campos importantes:
   - **PID (Process ID)**: Identificador único del proceso.
   - **Estado del proceso**: Indica si el proceso está en ejecución, en
     espera, listo, o terminado.
   - **Contador de programa (PC)**: Dirección de la siguiente
     instrucción que el proceso debe ejecutar.
   - **Registros de la CPU**: Incluyen el estado de los registros del procesador.
   - **Información de memoria**: Define las áreas de memoria asignadas al proceso.
   - **Información de I/O**: Lista de archivos o dispositivos abiertos por el proceso.
   - **Prioridad**: Define la importancia del proceso en relación a otros.

*** Estados del Proceso
Un proceso puede encontrarse en diferentes estados, y la tabla de procesos ayuda a rastrear el estado actual de cada proceso. Los estados típicos incluyen:
   - **Nuevo**: El proceso está siendo creado.
   - **Listo**: El proceso está esperando para ser ejecutado.
   - **En ejecución**: El proceso está utilizando la CPU.
   - **En espera/bloqueado**: El proceso espera un evento (como una operación de E/S).
   - **Terminado**: El proceso ha finalizado su ejecución.

*** Ejemplo en C de una Tabla de Procesos Simplificada
El siguiente ejemplo en C muestra cómo se puede representar una tabla
de procesos de manera simple mediante una estructura de datos.

#+BEGIN_SRC c
#include <stdio.h>
#include <string.h>
#define MAX_PROCESSES 5

// Definición de estructura para la tabla de procesos
typedef struct Process {
    int pid;                 // ID del proceso
    char state[20];          // Estado del proceso (ej: "Listo", "Ejecutando")
    int priority;            // Prioridad del proceso
    unsigned int pc;         // Contador de programa
} Process;

// Función para inicializar los procesos
void initializeProcesses(struct Process processes[], int size) {
    for (int i = 0; i < size; i++) {
        processes[i].pid = i + 1;
        strcpy(processes[i].state, "Listo");
        processes[i].priority = i % 3;  // Asigna prioridad de 0 a 2
        processes[i].pc = 0;
    }
}

// Función para mostrar la tabla de procesos
void displayProcessTable(struct Process processes[], int size) {
    printf("Tabla de Procesos:\n");
    printf("PID\tEstado\t\tPrioridad\tPC\n");
    printf("----\t-------\t\t---------\t----\n");
    for (int i = 0; i < size; i++) {
        printf("%d\t%s\t\t%d\t\t%u\n", 
               processes[i].pid, processes[i].state, processes[i].priority, processes[i].pc);
    }
}

// Función para simular el cambio de estado y actualizar el PC
void updateProcess(struct Process *process, const char *newState, unsigned int newPC) {
    strcpy(process->state, newState);
    process->pc = newPC;
}

int main() {
    struct Process processes[MAX_PROCESSES];

    initializeProcesses(processes, MAX_PROCESSES);  // Inicializa los procesos
    displayProcessTable(processes, MAX_PROCESSES);  // Muestra la tabla inicial

    printf("\nActualizando estado del proceso 1...\n");
    updateProcess(&processes[0], "Ejecutando", 100);  // Cambia el estado y PC del proceso 1
    displayProcessTable(processes, MAX_PROCESSES);    // Muestra la tabla actualizada

    return 0;
}
#+END_SRC

*** Explicación del Ejemplo
1. **Definición de Estructura**: La estructura `Process` representa cada proceso en la tabla. Incluye el **PID**, **estado**, **prioridad**, y **contador de programa (PC)**.
2. **Inicialización de Procesos**: La función `initializeProcesses` asigna un PID, establece el estado en "Listo", y asigna una prioridad a cada proceso.
3. **Visualización de la Tabla de Procesos**: La función `displayProcessTable` imprime la tabla de procesos, mostrando el estado actual de cada proceso.
4. **Actualización de un Proceso**: La función `updateProcess` permite cambiar el estado y el contador de programa de un proceso específico, simulando una transición de estado.

*** Salida Esperada
Al ejecutar el programa, la salida muestra la tabla de procesos inicial y después de actualizar el estado de un proceso.

: Tabla de Procesos:
: PID   Estado       Prioridad     PC
: ----  -------      ---------     ----
: 1     Listo        0             0
: 2     Listo        1             0
: 3     Listo        2             0
: 4     Listo        0             0
: 5     Listo        1             0

: Actualizando estado del proceso 1...
: Tabla de Procesos:
: PID   Estado       Prioridad     PC
: ----  -------      ---------     ----
: 1     Ejecutando   0             100
: 2     Listo        1             0
: 3     Listo        2             0
: 4     Listo        0             0
: 5     Listo        1             0

*** Conclusión
La tabla de procesos es fundamental para el seguimiento y administración
de los procesos en un sistema operativo. Cada proceso tiene su propio
bloque de control con información clave, y el sistema operativo
utiliza esta tabla para planificar, controlar y administrar los
recursos de cada proceso.






** Procesos ligeros: Hilos o hebras

Un proceso ligero o hilo es una unidad de ejecución que comparte el
mismo espacio de memoria que otros hilos dentro del mismo proceso. Los
hilos permiten paralelizar tareas en un programa y mejorar la
eficiencia sin crear procesos separados. Los sistemas operativos
modernos proporcionan bibliotecas como POSIX threads (pthreads) para
crear y gestionar hilos.

*** Ejemplo en C: Creación de hilos con pthread
#+BEGIN_SRC C :results output
#include <pthread.h>
#include <stdio.h>

void* tarea(void* arg) {
    printf("Hilo en ejecución\n");
    return NULL;
}

int main() {
    pthread_t hilo1, hilo2;
    pthread_create(&hilo1, NULL, tarea, NULL); 
    pthread_create(&hilo2, NULL, tarea, NULL);

    pthread_join(hilo1, NULL);
    pthread_join(hilo2, NULL);
    printf("Todos los hilos han terminado\n");
    return 0;
}
#+END_SRC

#+RESULTS:
: Hilo en ejecución
: Hilo en ejecución
: Todos los hilos han terminado

** pthread_create en C
*** Descripción de pthread_create
La función `pthread_create` en C se utiliza para crear y lanzar un
nuevo hilo de ejecución en un programa. Esta función es parte de la
biblioteca **POSIX Threads (pthreads)** y permite ejecutar tareas en
paralelo, lo cual es útil para mejorar el rendimiento y realizar
múltiples tareas de forma concurrente.

*** Sintaxis de pthread_create
#+BEGIN_SRC c
int pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine)(void *), void *arg);
#+END_SRC

*** Parámetros
- **`pthread_t *thread`**: Puntero a una variable de tipo `pthread_t`,
  que es el identificador del hilo que se está creando. Al terminar
  `pthread_create`, `*thread` contendrá un identificador único del
  hilo creado.
- **`const pthread_attr_t *attr`**: Atributos específicos del hilo. Si
  `attr` es `NULL`, se usarán los atributos predeterminados. Puedes
  configurar atributos personalizados con `pthread_attr_init` y
  `pthread_attr_set`.
- **`void *(*start_routine)(void *)`**: La función que ejecutará el
  hilo. Esta función debe ser de tipo `void*` y recibir un único
  argumento de tipo `void*`.
- **`void *arg`**: Argumento que se pasa a la función
  `start_routine`. Permite pasar datos al hilo; si no necesitas pasar
  datos, este parámetro puede ser `NULL`.

*** Valor de Retorno
- **0**: La función se ejecuta exitosamente y el hilo se crea sin problemas.
- **Distinto de 0**: Devuelve un código de error si la creación del hilo falla.

*** Ejemplo Práctico de pthread_create
Este ejemplo en C crea un hilo simple que imprime un mensaje
utilizando `pthread_create`:

#+BEGIN_SRC c
#include <pthread.h>
#include <stdio.h>
#include <stdlib.h>

void* tarea(void* arg) {
    int id = *(int*)arg; // Desreferenciar el puntero para obtener el ID
    printf("Hilo %d en ejecución\n", id);
    return NULL;
}

int main() {
    pthread_t hilo;
    int id = 1;

    // Crear el hilo
    if (pthread_create(&hilo, NULL, tarea, &id) != 0) {
        fprintf(stderr, "Error al crear el hilo\n");
        return 1;
    }

    // Esperar a que el hilo termine
    pthread_join(hilo, NULL);
    printf("El hilo ha terminado\n");
    return 0;
}
#+END_SRC

*** Explicación del Ejemplo
1. **Declaración de Hilo y Argumento**:
   - Se declara `pthread_t hilo` para almacenar el identificador del hilo.
   - Se crea una variable `id` con un valor de `1` que se pasa como argumento a la función del hilo.

2. **Llamada a `pthread_create`**:
   - `pthread_create` toma como primer argumento la dirección de `hilo` para almacenar el identificador.
   - `NULL` se usa como segundo argumento para utilizar los atributos predeterminados.
   - `tarea` es la función que el hilo ejecutará. Debe coincidir con el tipo `void* (*)(void*)`.
   - `&id` se pasa como argumento para que `tarea` reciba el valor del identificador del hilo.

3. **Ejecuta la Función `tarea` en el Hilo**:
   - `tarea` toma `arg` y lo desreferencia para obtener el valor de `id`.
   - La función imprime `"Hilo 1 en ejecución"` y luego termina.

4. **Espera a que el Hilo Termine con `pthread_join`**:
   - *pthread_join* se usa para esperar a que el hilo termine antes de que el programa principal continúe.
   - Una vez que el hilo finaliza, el programa principal imprime `"El hilo ha terminado"`.

*** Consideraciones Importantes
- **Sincronización**: *pthread_create* lanza el hilo inmediatamente,
  pero el hilo principal puede necesitar esperar a que el hilo termine
  usando *pthread_join*.
- **Paso de Argumentos**: Si necesitas pasar múltiples datos a la
  función del hilo, puedes crear una estructura para empaquetar todos
  los datos y pasar un puntero a esa estructura.
- **Atributos del Hilo**: Puedes controlar el tamaño de la pila, la
  prioridad, o hacer que el hilo sea "desvinculado" (no esperable)
  inicializando y configurando los atributos del hilo con
  *pthread_attr_init* y *pthread_attr_set*.

*** Resumen
La función *pthread_create* permite crear un nuevo hilo y especificar
la tarea que debe ejecutar, lo cual es útil para realizar múltiples
tareas en paralelo dentro del mismo programa, compartiendo memoria y
recursos, y controlando el comportamiento del hilo mediante su
identificador y atributos personalizados.


** cola con prioridad

#+BEGIN_SRC C
#include <stdio.h>
#include <stdlib.h>
#include <time.h>

typedef struct _nodo {
    int valor;
    int prioridad;
    struct _nodo *siguiente;
} nodo;

int numero_aleatorio() {
    return (rand() % 4) + 1;
}

nodo* genera_proceso() {
    static int contador = 1;
    nodo* nuevo = (nodo*)malloc(sizeof(nodo));
    if (nuevo == NULL) {
        printf("Error al asignar memoria.\n");
        exit(1);
    }
    nuevo->valor = contador++;
    nuevo->prioridad = numero_aleatorio();
    nuevo->siguiente = NULL;
    return nuevo;
}

void insertar_final(nodo** cabeza) {
    nodo* nuevoNodo = genera_proceso();

    if (*cabeza == NULL) {
        *cabeza = nuevoNodo;
    } else {
        nodo* temp = *cabeza;
        while (temp->siguiente != NULL) {
            temp = temp->siguiente;
        }
        temp->siguiente = nuevoNodo;
    }
}

void imprimir_lista(nodo* cabeza) {
    nodo* temp = cabeza;
    while (temp != NULL) {
        printf("Proceso %d (Prioridad %d) -> ", temp->valor, temp->prioridad);
        temp = temp->siguiente;
    }
    printf("NULL\n");
}

void atender_prioridad_mas_alta(nodo** cabeza) {
    if (*cabeza == NULL) {
        printf("No hay procesos para atender.\n");
        return;
    }

    nodo* temp = *cabeza;
    nodo* maxNodo = temp;
    nodo* maxNodoPrevio = NULL;
    nodo* previo = NULL;

    // Buscar el nodo con la prioridad más alta
    while (temp != NULL) {
        if (temp->prioridad > maxNodo->prioridad) {
            maxNodo = temp;
            maxNodoPrevio = previo;
        }
        previo = temp;
        temp = temp->siguiente;
    }

    // Atender el nodo con prioridad más alta
    printf("Atendiendo proceso %d con prioridad %d\n", maxNodo->valor, maxNodo->prioridad);

    // Eliminar el nodo de la lista
    if (maxNodoPrevio == NULL) {
        *cabeza = maxNodo->siguiente;  // El nodo con mayor prioridad es la cabeza
    } else {
        maxNodoPrevio->siguiente = maxNodo->siguiente;
    }

    free(maxNodo);
}

int main() {
    srand(time(NULL));
    nodo* cabeza = NULL;
    int op = 0;

    do {
        printf("1. Genera proceso\n");
        printf("2. Atiende proceso\n");
        printf("3. Mostrar Lista de Procesos\n");
        printf("4. Salir\n");
        printf("Seleccione una opción: ");
        scanf("%d", &op);

        switch (op) {
            case 1:
                insertar_final(&cabeza);
                break;
            case 2:
                atender_prioridad_mas_alta(&cabeza);
                break;
            case 3:
                imprimir_lista(cabeza);
                break;
            case 4:
                printf("Saliendo...\n");
                break;
            default:
                printf("Opción no válida\n");
        }
    } while (op != 4);

    return 0;
}


#+end_src




** Concurrencia y Secuenciabilidad 

La concurrencia y secuenciabilidad son conceptos clave en el diseño
y la gestión de sistemas operativos modernos. Permiten que
múltiples procesos y threads se ejecuten de manera simultánea o
alternada en un sistema, maximizando la utilización de recursos y
mejorando la eficiencia general del sistema. 

La concurrencia permite ejecutar múltiples tareas
"simultáneamente". Aunque no siempre se ejecutan al mismo tiempo, se
pueden intercalar en un mismo procesador mediante interrupciones y
cambios de contexto. La secuenciabilidad define un orden en estas
tareas concurrentes, permitiendo que se ejecute un bloque de código
mientras otro espera, garantizando la sincronización. En sistemas de
múltiples núcleos, esto puede significar ejecución paralela, mientras
que en sistemas de un solo núcleo implica cambios de contexto rápidos.

- *Objetivo*: Permitir que múltiples procesos compartan el CPU y otros
  recursos de manera eficiente y sin conflictos.
- *Desafíos*: Sincronización de acceso a recursos compartidos, evitar
  condiciones de carrera y gestionar la exclusión mutua.


*** Ejemplo en C: Concurrencia y sincronización de tareas
#+BEGIN_SRC C :results output
#include <pthread.h>
#include <stdio.h>
#include <unistd.h>

void* tarea1(void* arg) {
    printf("Inicio de tarea 1\n");
    sleep(1);
    printf("Fin de tarea 1\n");
    return NULL;
}

void* tarea2(void* arg) {
    printf("Inicio de tarea 2\n");
    sleep(1);
    printf("Fin de tarea 2\n");
    return NULL;
}

int main() {
    pthread_t hilo1, hilo2;
    pthread_create(&hilo1, NULL, tarea1, NULL);
    pthread_create(&hilo2, NULL, tarea2, NULL);

    pthread_join(hilo1, NULL);
    pthread_join(hilo2, NULL);
    printf("Ambas tareas han terminado de forma concurrente\n");
    return 0;
}
#+END_SRC

#+RESULTS:
: Inicio de tarea 1
: Inicio de tarea 2
: Fin de tarea 2
: Fin de tarea 1
: Ambas tareas han terminado de forma concurrente

   
*** 1.1 Exclusión Mutua
 La exclusión mutua asegura que solo un proceso a la vez pueda acceder
 a una sección crítica que manipula recursos compartidos.
    - Algoritmos comunes:
      - Algoritmo de Dekker
      - Algoritmo de Peterson
      - Algoritmo de Lamport’s Bakery
      - Semáforos y Mutexes


**** 1. Algoritmo de Dekker
El algoritmo de Dekker es un algoritmo de programación concurrente
para exclusión mutua, que permite a dos procesos o hilos de ejecución
compartir un recurso sin conflictos. Fue uno de los primeros
algoritmos de exclusión mutua inventados, implementado por Edsger
Dijkstra.

Si ambos procesos intentan acceder a la sección crítica
simultáneamente, el algoritmo elige un proceso según una variable de
turno. Si el otro proceso está ejecutando en su sección crítica,
deberá esperar su finalización.

***** Condiciones

- No hay prioridad entre procesos.
- La capacidad de los equipos es irrelevante.
- Si un proceso muere fuera de la región crítica, el algoritmo sigue funcionando.
- Un bloqueo mutuo no se considera como solución válida.

Existen cinco versiones del algoritmo Dekker, teniendo ciertos fallos
los primeros cuatro. La versión 5 es la que trabaja más
eficientemente, siendo una combinación de la 1 y la 4.

- Versión 1: Alternancia estricta. Garantiza la exclusión mutua, pero
  su desventaja es que acopla los procesos fuertemente, esto significa
  que los procesos lentos atrasan a los procesos rápidos.
- Versión 2: Problema interbloqueo. No existe la alternancia, aunque
  ambos procesos caen a un mismo estado y nunca salen de ahí.
- Versión 3: Colisión región crítica no garantiza la exclusión
  mutua. Este algoritmo no evita que dos procesos puedan acceder al
  mismo tiempo a la región crítica.
- Versión 4: Postergación indefinida. Aunque los procesos no están en
  interbloqueo, un proceso o varios se quedan esperando a que suceda
  un evento que tal vez nunca suceda.

- *Variables*: `flag[2]` es un arreglo booleano donde `flag[i]` indica
  si el proceso `i` desea entrar en la sección crítica.
- *Turno*: `turn` indica el turno de los procesos para entrar en la sección crítica.

- *Matemática*:
  - Condiciones de entrada a la sección crítica:
   1. Si un proceso quiere entrar, establece `flag[i] = true`.
   2. Si el otro proceso también quiere entrar, se usa la variable
      `turn` para determinar quién tiene prioridad.
   3. Un proceso entra a la sección crítica si `flag[j] == false` o `turn == i`.

Ejemplo de del algoritmo de Dekker en C
       

 #+BEGIN_SRC C :results output
 #include <stdio.h>
 #include <pthread.h>
 #include <stdbool.h>

 bool flag[2] = {false, false};
 int turn = 0;

 void* proceso(void* arg) {
     int i = *(int*)arg;
     int j = 1 - i;
     flag[i] = true;
     while (flag[j]) {
         if (turn != i) {
             flag[i] = false;
             while (turn != i);
             flag[i] = true;
         }
     }
     // Sección Crítica
     printf("Proceso %d en sección crítica\n", i);
     turn = j;
     flag[i] = false;
     
 }

 int main() {
     pthread_t t0, t1;
     int id0 = 0, id1 = 1;
     pthread_create(&t0, NULL, proceso, &id0);
     pthread_create(&t1, NULL, proceso, &id1);
     pthread_join(t0, NULL);
     pthread_join(t1, NULL);
     return 0;
 }
 #+END_SRC

 #+RESULTS:
 : Proceso 0 en sección crítica
 : Proceso 1 en sección crítica


***** Productor Consumidor Dekker

#+BEGIN_SRC C :results output :tangle code/pcdekker.c
#include <stdio.h>
#include <stdlib.h>
#include <pthread.h>
#include <unistd.h>

typedef struct _nodo {
    int valor;
    struct _nodo *siguiente;
} nodo;

nodo* cabeza = NULL; // Cola de procesos

int turno = 0;           // Variable de turno para el algoritmo de Dekker
int interesado[2] = {0, 0};  // Indica si el productor o consumidor están interesados

void insertar_final(int valor) {
    nodo* nuevo = (nodo*)malloc(sizeof(nodo));
    nuevo->valor = valor;
    nuevo->siguiente = cabeza;
    cabeza = nuevo;
    printf("Productor produjo: %d\n", valor);
}

void atender_proceso() {
    if (cabeza != NULL) {
        nodo* temp = cabeza;
        cabeza = cabeza->siguiente;
        printf("Consumidor atendió: %d\n", temp->valor);
        free(temp);
    } else {
        printf("No hay procesos para consumir\n");
    }
}

// Función de productor utilizando algoritmo de Dekker
void* productor(void* arg) {
    for (int i = 0; i < 5; i++) {
        interesado[0] = 1;
        while (interesado[1]) {
            if (turno != 0) {
                interesado[0] = 0;
                while (turno != 0);
                interesado[0] = 1;
            }
        }
        
        insertar_final(i + 1); // Zona crítica
        
        turno = 1;
        interesado[0] = 0;
        sleep(1); // Simular producción
    }
    return NULL;
}

// Función de consumidor utilizando algoritmo de Dekker
void* consumidor(void* arg) {
    for (int i = 0; i < 5; i++) {
        interesado[1] = 1;
        while (interesado[0]) {
            if (turno != 1) {
                interesado[1] = 0;
                while (turno != 1);
                interesado[1] = 1;
            }
        }
        
        atender_proceso(); // Zona crítica
        
        turno = 0;
        interesado[1] = 0;
        sleep(1); // Simular consumo
    }
    return NULL;
}

int main() {
    pthread_t hilo_productor, hilo_consumidor;
    
    pthread_create(&hilo_productor, NULL, productor, NULL);
    pthread_create(&hilo_consumidor, NULL, consumidor, NULL);
    
    pthread_join(hilo_productor, NULL);
    pthread_join(hilo_consumidor, NULL);
    
    return 0;
}

#+END_SRC


 
**** 2. Algoritmo de Peterson
El algoritmo de Peterson, también conocido como solución de
Peterson,​ es un algoritmo de programación concurrente para exclusión
mutua, que permite a dos o más procesos o hilos de ejecución compartir
un recurso sin conflictos, utilizando sólo memoria compartida para la
comunicación.

Gary L. Peterson desarrolló en 1981 el algoritmo básico para dos
procesos, como una simplificación del algoritmo de Dekker. El
algoritmo básico puede generalizarse fácilmente a un número arbitrario
de procesos.3​

Este algoritmo es una mejora sobre Dekker, asegurando exclusión mutua
con dos procesos de manera más simple y sin necesidad de turnos
adicionales.

- *Variables*: `flag[2]` es un arreglo booleano que indica si el proceso
  desea entrar en la sección crítica. `turn` indica el proceso que
  tiene prioridad para entrar.
- *Condición de espera*: El proceso espera si el otro también quiere
  entrar y si es su turno.

 - *Matemática*:
   - Exclusión mutua garantizada porque solo un proceso podrá cumplir
     `flag[j] == false || turn == i`.


Ejemplo de del algoritmo de Peterson en C

#+BEGIN_SRC C
#include <stdio.h>
#include <pthread.h>
#include <stdbool.h>

bool flag[2] = {false, false};
int turn;

void* proceso(void* arg) {
    int i = *(int*)arg;
    int j = 1 - i;
    flag[i] = true;
    turn = j;
    while (flag[j] && turn == j);
    // Sección Crítica
    printf("Proceso %d en sección crítica\n", i);
    flag[i] = false;
    return NULL;
}

int main() {
    pthread_t t0, t1;
    int id0 = 0, id1 = 1;
    pthread_create(&t0, NULL, proceso, &id0);
    pthread_create(&t1, NULL, proceso, &id1);
    pthread_join(t0, NULL);
    pthread_join(t1, NULL);
    return 0;
}
#+END_SRC

***** Productor Consumidor 
#+BEGIN_SRC C :results output code/pclampor.c
#include <stdio.h>
#include <stdlib.h>
#include <pthread.h>
#include <unistd.h>

#define MAX_PROCESOS 10

typedef struct _nodo {
    int valor;
    int prioridad;
    struct _nodo *siguiente;
} nodo;

nodo* cabeza = NULL;

int turno = 0;
int interesado[2] = {0, 0};

int numero_aleatorio() {
    return (rand() % 4) + 1;
}

nodo* genera_proceso(int id) {
    nodo* nuevo = (nodo*)malloc(sizeof(nodo));
    nuevo->valor = id;
    nuevo->prioridad = numero_aleatorio();
    nuevo->siguiente = NULL;
    return nuevo;
}

void* productor(void* arg) {
    int id = *(int*)arg;
    for (int i = 0; i < 5; i++) {
        interesado[0] = 1;
        turno = 1;
        while (interesado[1] && turno == 1);

        nodo* nuevo = genera_proceso(id * 10 + i);
        nuevo->siguiente = cabeza;
        cabeza = nuevo;
        printf("Productor %d generó proceso %d con prioridad %d\n", id, nuevo->valor, nuevo->prioridad);

        interesado[0] = 0;
        sleep(1);
    }
    return NULL;
}

void* consumidor(void* arg) {
    int id = *(int*)arg;
    for (int i = 0; i < 5; i++) {
        interesado[1] = 1;
        turno = 0;
        while (interesado[0] && turno == 0);

        if (cabeza != NULL) {
            nodo* temp = cabeza;
            cabeza = cabeza->siguiente;
            printf("Consumidor %d atendió proceso %d con prioridad %d\n", id, temp->valor, temp->prioridad);
            free(temp);
        } else {
            printf("No hay procesos para consumir\n");
        }

        interesado[1] = 0;
        sleep(1);
    }
    return NULL;
}

int main() {
    srand(time(NULL));
    pthread_t hilo_productor, hilo_consumidor;
    int id_productor = 1, id_consumidor = 2;

    pthread_create(&hilo_productor, NULL, productor, &id_productor);
    pthread_create(&hilo_consumidor, NULL, consumidor, &id_consumidor);

    pthread_join(hilo_productor, NULL);
    pthread_join(hilo_consumidor, NULL);

    return 0;
}

#+END_SRC

**** 3. Algoritmo de Lamport’s Bakery
El algoritmo de Lamport’s Bakery es una generalización que permite la
exclusión mutua para múltiples procesos, usando una "numeración"
similar a la de una panadería.

El algoritmo de la panadería toma su nombre de la costumbre de las
panaderías y tiendas en general, donde las personas al entrar al local
obtienen un número de turno (único) y lo utilizan para que el
dependiente les vaya atendiendo en orden de llegada. El cliente
obtiene su número de turno usando una cinta de papel que ofrece
boletos con números consecutivos.

El dependiente sólo puede atender a una persona al mismo tiempo, lo
que concuerda con el uso de un recurso de forma exclusiva: el recurso
es el dependiente y la sección crítica de un cliente es lo que realiza
mientras es atendido.

Panaderia 
|1|->|2|->|3|->|4|->|5|

- *Variables*: `number[i]` representa el turno del proceso `i`. El valor más bajo en `number[i]` representa el turno de prioridad.
- *Matemática*:
  - Cada proceso `i` toma un "ticket" (el valor más alto de `number[j] + 1`) antes de entrar en la sección crítica.
  - El proceso entra en la sección crítica si su "ticket" es el menor o si su índice `i` es menor en caso de empate en el ticket.

Ejemplo de del algoritmo de Lamport’s Bakery en C

#+BEGIN_SRC C
       #include <stdio.h>
       #include <pthread.h>
       #include <stdbool.h>

       #define NUM_PROCESOS 3
       bool choosing[NUM_PROCESOS];
       int number[NUM_PROCESOS];

       void* proceso(void* arg) {
           int i = *(int*)arg;

           choosing[i] = true;
           number[i] = 1;
           for (int j = 0; j < NUM_PROCESOS; j++) {
               if (number[j] > number[i]) number[i] = number[j] + 1;
           }
           choosing[i] = false;

           for (int j = 0; j < NUM_PROCESOS; j++) {
               while (choosing[j]);
               while (number[j] != 0 && (number[j] < number[i] || (number[j] == number[i] && j < i)));
           }

           printf("Proceso %d en sección crítica\n", i);

           number[i] = 0;
           return NULL;
       }

       int main() {
           pthread_t threads[NUM_PROCESOS];
           int ids[NUM_PROCESOS];
           for (int i = 0; i < NUM_PROCESOS; i++) {
               ids[i] = i;
               pthread_create(&threads[i], NULL, proceso, &ids[i]);
           }
           for (int i = 0; i < NUM_PROCESOS; i++) {
               pthread_join(threads[i], NULL);
           }
           return 0;
       }
       #+END_SRC

**** Productor Consumidor 
#+BEGIN_SRC C :results output code/pclampor.c
#include <stdio.h>
#include <stdlib.h>
#include <pthread.h>
#include <unistd.h>

#define MAX_PROCESOS 10

typedef struct _nodo {
    int valor;
    int prioridad;
    struct _nodo *siguiente;
} nodo;

nodo* cabeza = NULL;

int turno[2];
int eligiendo[2] = {0, 0};

int numero_aleatorio() {
    return (rand() % 4) + 1;
}

nodo* genera_proceso(int id) {
    nodo* nuevo = (nodo*)malloc(sizeof(nodo));
    nuevo->valor = id;
    nuevo->prioridad = numero_aleatorio();
    nuevo->siguiente = NULL;
    return nuevo;
}

int max_turno() {
    return turno[0] > turno[1] ? turno[0] : turno[1];
}

void* productor(void* arg) {
    int id = *(int*)arg;
    for (int i = 0; i < 5; i++) {
        eligiendo[0] = 1;
        turno[0] = max_turno() + 1;
        eligiendo[0] = 0;

        while (eligiendo[1]);
        while (turno[1] != 0 && (turno[1] < turno[0] || (turno[1] == turno[0] && 1 < 0)));

        nodo* nuevo = genera_proceso(id * 10 + i);
        nuevo->siguiente = cabeza;
        cabeza = nuevo;
        printf("Productor %d generó proceso %d con prioridad %d\n", id, nuevo->valor, nuevo->prioridad);

        turno[0] = 0;
        sleep(1);
    }
    return NULL;
}

void* consumidor(void* arg) {
    int id = *(int*)arg;
    for (int i = 0; i < 5; i++) {
        eligiendo[1] = 1;
        turno[1] = max_turno() + 1;
        eligiendo[1] = 0;

        while (eligiendo[0]);
        while (turno[0] != 0 && (turno[0] < turno[1] || (turno[0] == turno[1] && 0 < 1)));

        if (cabeza != NULL) {
            nodo* temp = cabeza;
            cabeza = cabeza->siguiente;
            printf("Consumidor %d atendió proceso %d con prioridad %d\n", id, temp->valor, temp->prioridad);
            free(temp);
        } else {
            printf("No hay procesos para consumir\n");
        }

        turno[1] = 0;
        sleep(1);
    }
    return NULL;
}

int main() {
    srand(time(NULL));
    pthread_t hilo_productor, hilo_consumidor;
    int id_productor = 1, id_consumidor = 2;

    pthread_create(&hilo_productor, NULL

#+END_SRC
	   
**** 4. Semáforos y Mutexes


   Los semáforos y mutexes son mecanismos ampliamente utilizados para
   manejar la sincronización y exclusión mutua en sistemas operativos
   y multihilos.

   - *Semáforo*: Un contador que controla el acceso de múltiples threads
     a un recurso compartido.
     - `wait` (P): Decrementa el contador del semáforo. Si es
       negativo, el proceso espera.
     - `signal` (V): Incrementa el contador, liberando un proceso en espera.
   - *Mutex*: Similar a un semáforo binario, asegura que solo un thread
     acceda a la sección crítica.


Ejemplo de del algoritmo de Semáforos y Mutexes en C
   

#+BEGIN_SRC C
       #include <stdio.h>
       #include <pthread.h>
       #include <semaphore.h>

       sem_t semaforo;

       void* proceso(void* arg) {
           sem_wait(&semaforo); // Entrada en la sección crítica
           printf("Proceso en sección crítica\n");
           sem_post(&semaforo); // Salida de la sección crítica
           return NULL;
       }

       int main() {
           pthread_t t1, t2;
           sem_init(&semaforo, 0, 1); // Inicializa el semáforo con valor 1
           pthread_create(&t1, NULL, proceso, NULL);
           pthread_create(&t2, NULL, proceso, NULL);
           pthread_join(t1, NULL);
           pthread_join(t2, NULL);
           sem_destroy(&semaforo);
           return 0;
       }
       #+END_SRC


#+BEGIN_SRC C :results output :tangle code/colasemaforomutex.c
#include <stdio.h>
#include <stdlib.h>
#include <time.h>
#include <pthread.h>

typedef struct _nodo {
    int valor;
    int prioridad;
    struct _nodo *siguiente;
} nodo;

pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER; // Inicializar el mutex para la sincronización

int numero_aleatorio() {
    return (rand() % 4) + 1;
}

nodo* genera_proceso() {
    static int contador = 1;
    nodo* nuevo = (nodo*)malloc(sizeof(nodo));
    if (nuevo == NULL) {
        printf("Error al asignar memoria.\n");
        exit(1);
    }
    nuevo->valor = contador++;
    nuevo->prioridad = numero_aleatorio();
    nuevo->siguiente = NULL;
    return nuevo;
}

void insertar_final(nodo** cabeza) {
    pthread_mutex_lock(&mutex); // Bloquear el acceso a la lista
    nodo* nuevoNodo = genera_proceso();

    if (*cabeza == NULL) {
        *cabeza = nuevoNodo;
    } else {
        nodo* temp = *cabeza;
        while (temp->siguiente != NULL) {
            temp = temp->siguiente;
        }
        temp->siguiente = nuevoNodo;
    }
    pthread_mutex_unlock(&mutex); // Liberar el acceso a la lista
}

void imprimir_lista(nodo* cabeza) {
    pthread_mutex_lock(&mutex); // Bloquear el acceso a la lista
    nodo* temp = cabeza;
    while (temp != NULL) {
        printf("Proceso %d (Prioridad %d) -> ", temp->valor, temp->prioridad);
        temp = temp->siguiente;
    }
    printf("NULL\n");
    pthread_mutex_unlock(&mutex); // Liberar el acceso a la lista
}

void atender_prioridad_mas_alta(nodo** cabeza) {
    pthread_mutex_lock(&mutex); // Bloquear el acceso a la lista
    if (*cabeza == NULL) {
        printf("No hay procesos para atender.\n");
        pthread_mutex_unlock(&mutex); // Liberar el acceso a la lista
        return;
    }

    nodo* temp = *cabeza;
    nodo* maxNodo = temp;
    nodo* maxNodoPrevio = NULL;
    nodo* previo = NULL;

    // Buscar el nodo con la prioridad más alta
    while (temp != NULL) {
        if (temp->prioridad > maxNodo->prioridad) {
            maxNodo = temp;
            maxNodoPrevio = previo;
        }
        previo = temp;
        temp = temp->siguiente;
    }

    // Atender el nodo con prioridad más alta
    printf("Atendiendo proceso %d con prioridad %d\n", maxNodo->valor, maxNodo->prioridad);

    // Eliminar el nodo de la lista
    if (maxNodoPrevio == NULL) {
        *cabeza = maxNodo->siguiente;  // El nodo con mayor prioridad es la cabeza
    } else {
        maxNodoPrevio->siguiente = maxNodo->siguiente;
    }

    free(maxNodo);
    pthread_mutex_unlock(&mutex); // Liberar el acceso a la lista
}

int main() {
    srand(time(NULL));
    nodo* cabeza = NULL;
    int op = 0;

    do {
        printf("1. Genera proceso\n");
        printf("2. Atiende proceso\n");
        printf("3. Mostrar Lista de Procesos\n");
        printf("4. Salir\n");
        printf("Seleccione una opción: ");
        scanf("%d", &op);

        switch (op) {
            case 1:
                insertar_final(&cabeza);
                break;
            case 2:
                atender_prioridad_mas_alta(&cabeza);
                break;
            case 3:
                imprimir_lista(cabeza);
                break;
            case 4:
                printf("Saliendo...\n");
                break;
            default:
                printf("Opción no válida\n");
        }
    } while (op != 4);

    pthread_mutex_destroy(&mutex); // Destruir el mutex al finalizar
    return 0;
}

#+END_SRC

***** Productor Consumidos

#+BEGIN_SRC C :results output :tangle code/pcsemaforomutex.c
#include <stdio.h>
#include <stdlib.h>
#include <pthread.h>
#include <semaphore.h>
#include <unistd.h>

#define MAX_PROCESOS 10  // Capacidad máxima de la cola de procesos
#define NUM_PRODUCTORES 3
#define NUM_CONSUMIDORES 2

typedef struct _nodo {
    int valor;
    int prioridad;
    struct _nodo *siguiente;
} nodo;

nodo* cabeza = NULL; // Cabeza de la lista de procesos
pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER; // Mutex para sincronizar acceso a la lista
sem_t espacios; // Semáforo para los espacios libres en la cola
sem_t elementos; // Semáforo para los elementos presentes en la cola

int numero_aleatorio() {
    return (rand() % 4) + 1;
}

// Genera un nuevo proceso
nodo* genera_proceso(int id) {
    nodo* nuevo = (nodo*)malloc(sizeof(nodo));
    if (nuevo == NULL) {
        printf("Error al asignar memoria.\n");
        exit(1);
    }
    nuevo->valor = id;
    nuevo->prioridad = numero_aleatorio();
    nuevo->siguiente = NULL;
    return nuevo;
}

// Función para que el productor agregue procesos a la cola
void* productor(void* arg) {
    int id = *(int*)arg;
    for (int i = 0; i < 5; i++) { // Cada productor produce 5 procesos
        sem_wait(&espacios); // Espera a que haya espacio en la cola
        nodo* nuevo = genera_proceso(id * 10 + i);

        pthread_mutex_lock(&mutex); // Bloqueo de acceso a la cola
        nuevo->siguiente = cabeza;
        cabeza = nuevo;
        printf("Productor %d generó proceso %d con prioridad %d\n", id, nuevo->valor, nuevo->prioridad);
        pthread_mutex_unlock(&mutex); // Liberar acceso a la cola

        sem_post(&elementos); // Incrementa el contador de elementos
        sleep(1); // Simula tiempo de producción
    }
    pthread_exit(NULL);
}

// Función para que el consumidor retire y procese el elemento con mayor prioridad
void* consumidor(void* arg) {
    int id = *(int*)arg;
    while (1) {
        sem_wait(&elementos); // Espera a que haya elementos en la cola

        pthread_mutex_lock(&mutex); // Bloqueo de acceso a la cola
        // Buscar el proceso de mayor prioridad
        nodo* temp = cabeza;
        nodo* maxNodo = temp;
        nodo* maxNodoPrevio = NULL;
        nodo* previo = NULL;

        while (temp != NULL) {
            if (temp->prioridad > maxNodo->prioridad) {
                maxNodo = temp;
                maxNodoPrevio = previo;
            }
            previo = temp;
            temp = temp->siguiente;
        }

        // Procesar el nodo de mayor prioridad
        if (maxNodoPrevio == NULL) {
            cabeza = maxNodo->siguiente;
        } else {
            maxNodoPrevio->siguiente = maxNodo->siguiente;
        }

        printf("Consumidor %d atendiendo proceso %d con prioridad %d\n", id, maxNodo->valor, maxNodo->prioridad);
        free(maxNodo); // Liberar el proceso de la memoria
        pthread_mutex_unlock(&mutex); // Liberar acceso a la cola

        sem_post(&espacios); // Incrementa el contador de espacios libres
        sleep(1); // Simula tiempo de procesamiento
    }
}

int main() {
    srand(time(NULL));
    pthread_t productores[NUM_PRODUCTORES];
    pthread_t consumidores[NUM_CONSUMIDORES];
    int ids_productores[NUM_PRODUCTORES];
    int ids_consumidores[NUM_CONSUMIDORES];

    sem_init(&espacios, 0, MAX_PROCESOS); // Inicializa el semáforo de espacios con el tamaño máximo de la cola
    sem_init(&elementos, 0, 0); // Inicializa el semáforo de elementos en 0, ya que la cola está inicialmente vacía

    // Crear hilos productores
    for (int i = 0; i < NUM_PRODUCTORES; i++) {
        ids_productores[i] = i + 1;
        pthread_create(&productores[i], NULL, productor, &ids_productores[i]);
    }

    // Crear hilos consumidores
    for (int i = 0; i < NUM_CONSUMIDORES; i++) {
        ids_consumidores[i] = i + 1;
        pthread_create(&consumidores[i], NULL, consumidor, &ids_consumidores[i]);
    }

    // Esperar a que los productores terminen
    for (int i = 0; i < NUM_PRODUCTORES; i++) {
        pthread_join(productores[i], NULL);
    }

    // Terminar el programa después de un tiempo
    sleep(10); // Permitir que los consumidores trabajen un poco antes de finalizar
    printf("Finalizando...\n");

    // Liberar los recursos
    sem_destroy(&espacios);
    sem_destroy(&elementos);
    pthread_mutex_destroy(&mutex);
    return 0;
}

#+END_SRC


	   
*** 1.2 Sincronización
    La sincronización se encarga de coordinar la ejecución de
    múltiples procesos o threads para garantizar que operen de manera
    ordenada.
    - *Semáforos de Dijkstra*: Usados para la sincronización y control
      de acceso a recursos mediante dos tipos:
      - Semáforo binario (mutex)
      - Semáforo contador (permite múltiples accesos)
    - *Monitores*: Estructuras que permiten que los procesos esperen
      hasta que una condición se cumpla.
    
*** 1.3 Condiciones de carrera y sincronización
    Las condiciones de carrera ocurren cuando dos o más procesos acceden a recursos compartidos de manera concurrente y el resultado depende del orden de ejecución. Esto se soluciona con:
    - Bloqueos de exclusión mutua.
    - Sincronización a través de semáforos y monitores.

** Secuenciabilidad
   La secuenciabilidad implica gestionar el orden de ejecución de los
   procesos o threads en un sistema operativo para asegurar que se
   cumplan ciertos requisitos de rendimiento o justicia en el acceso a
   recursos. Es fundamental para la planificación de procesos.
   
   - *Objetivo*: Asignar CPU a los procesos de forma que se minimicen
     tiempos de espera y maximicen el uso del procesador.
   
*** 2.1 Algoritmos de Planificación de Procesos
    Los algoritmos de planificación determinan el orden en que se
    ejecutan los procesos en la CPU. Los más comunes incluyen:
    - *First-Come, First-Served (FCFS)*: Los procesos se ejecutan en el orden de llegada.
    - *Shortest Job Next (SJN)*: El proceso con el tiempo de ejecución
      más corto tiene prioridad.
    - *Round Robin (RR)*: Cada proceso recibe una cantidad fija de
      tiempo de CPU, después de la cual pasa al final de la cola.
    - *Multilevel Queue Scheduling*: Los procesos se agrupan en diferentes colas, cada una con su propio algoritmo de planificación.
    - *Priority Scheduling*: Los procesos con mayor prioridad se
      ejecutan primero, lo cual requiere un manejo cuidadoso para
      evitar el "hambruna" de procesos de baja prioridad.

*** 2.2 Algoritmos de Detección y Prevención de Interbloqueos (Deadlocks)
    Los interbloqueos ocurren cuando dos o más procesos esperan
    indefinidamente por recursos que otros procesos poseen.
    - *Condiciones para un Interbloqueo*:
      - Exclusión mutua
      - Retención y espera
      - No apropiación
      - Espera circular

    - *Métodos de Prevención*:
      - *Algoritmo del banquero de Dijkstra*: Evalúa si la asignación de
        recursos puede llevar a un estado seguro o potencialmente
        inseguro.
      - *Prevención de interbloqueos*: Evita que se cumplan las
        condiciones para un interbloqueo.

*** 2.3 Sincronización y Secuenciabilidad
    La sincronización y secuenciabilidad son clave para evitar
    conflictos y maximizar el rendimiento. Se utilizan técnicas como:
    - *Wait-for Graphs*: Muestran dependencias de recursos para detectar
      posibles interbloqueos.
    - *Petri Nets*: Herramientas visuales para analizar sistemas
      concurrentes y modelar sincronización y secuenciabilidad.

*** 3. Conclusión
La concurrencia y secuenciabilidad son fundamentales en la gestión de
sistemas operativos modernos. Los algoritmos y métodos descritos
permiten el uso eficiente de recursos, minimizan los tiempos de espera
y evitan conflictos entre procesos. Comprender estos conceptos y sus
implementaciones es esencial para el desarrollo de sistemas operativos
y aplicaciones robustas en entornos concurrentes.




** Niveles, Objetivos y Criterios de Planificación
La planificación es el proceso de asignar recursos del sistema a los
procesos, y su objetivo principal es optimizar el rendimiento del
sistema en función de ciertos criterios como el tiempo de respuesta,
la eficiencia y la equidad. Existen varios niveles de planificación,
que determinan cómo se gestionan los procesos en diferentes etapas de
su ciclo de vida.

*** Niveles de Planificación
   - **Planificación a largo plazo**: 
     - Este nivel de planificación se encarga de seleccionar qué procesos deben entrar en el sistema para su ejecución. 
     - Controla el grado de multiprogramación del sistema, es decir, el número de procesos que se ejecutan en un momento dado.
     - Decisiones de planificación a largo plazo suelen tomarse con menor frecuencia y se realizan en sistemas de tipo batch o procesamiento por lotes.
   - **Planificación a medio plazo**:
     - Se encarga de manejar los procesos que están en espera o en suspensión, decidiendo cuáles de ellos pasarán a estado "listo" para su ejecución.
     - Es importante en sistemas donde existe una limitación de recursos, ya que ayuda a equilibrar la carga liberando o activando procesos según el estado de los recursos del sistema.
     - Este nivel ayuda a optimizar la eficiencia en sistemas donde algunos procesos deben esperar debido a la disponibilidad limitada de memoria o CPU.
   - **Planificación a corto plazo**:
     - Este nivel se encarga de seleccionar cuál de los procesos en estado "listo" va a ser ejecutado por la CPU.
     - Es el nivel más frecuente de planificación y su objetivo es minimizar el tiempo de inactividad de la CPU, cambiando de proceso rápidamente.
     - Los algoritmos de planificación a corto plazo incluyen Round Robin, SJF y planificación por prioridad.

*** Objetivos de la Planificación
   - **Optimización del tiempo de respuesta**: Especialmente importante en sistemas interactivos, donde los usuarios esperan respuestas rápidas.
   - **Maximización del rendimiento**: Ejecutar la mayor cantidad de procesos posible en un tiempo determinado.
   - **Equidad**: Asegurar que todos los procesos tengan una oportunidad justa de utilizar la CPU y evitar la inanición o starvation de procesos.
   - **Minimización del tiempo de espera**: Reducir el tiempo que un proceso permanece en la cola esperando ser ejecutado.

*** Criterios de Planificación
   - **Equidad**: El sistema debe asignar recursos de manera equitativa, evitando el bloqueo de procesos de baja prioridad.
   - **Eficiencia**: Aumentar la utilización de la CPU al máximo, minimizando el tiempo de inactividad.
   - **Tiempo de respuesta**: Reducir el tiempo que tarda el sistema en responder a una solicitud del usuario.
   - **Tiempo de espera**: Minimizar el tiempo que un proceso pasa esperando en la cola de "listos".
   - **Tiempo de retorno**: Minimizar el tiempo total que un proceso tarda desde que se envía hasta que finaliza.

*** Ejemplo en C: Implementación Simple de Planificación Round Robin
El siguiente código en C es una implementación simple de un esquema de
planificación Round Robin. En este ejemplo, se simulan tres procesos
que se ejecutan en un bucle y cada proceso tiene un intervalo de
tiempo fijo para su ejecución.

#+BEGIN_SRC C :results output
#include <stdio.h>
#include <unistd.h>

void proceso(int id) {
    printf("Proceso %d en ejecución\n", id);
    sleep(1); // Tiempo simulado de ejecución del proceso
    printf("Proceso %d terminado\n", id);
}

int main() {
    int n_procesos = 3;
    for (int i = 0; i < n_procesos; i++) {
        proceso(i);
    }
    return 0;
}
#+END_SRC

#+RESULTS:

** Técnicas de Administración del Planificador
El planificador utiliza varias técnicas para mejorar la gestión de
procesos y optimizar el rendimiento del sistema. Algunas de las
técnicas principales incluyen:

   - **Round Robin**: 
     - En este algoritmo, cada proceso recibe una franja de tiempo
       fija (quantum) para su ejecución.
     - Si un proceso no se completa durante su quantum, se coloca al
       final de la cola de procesos listos, y la CPU se asigna al
       siguiente proceso.
     - Es una técnica equitativa y adecuada para sistemas de tiempo
       compartido, aunque el tamaño del quantum debe elegirse con
       cuidado.
   
   - **Prioridad**:
     - Este algoritmo asigna a cada proceso una prioridad, y los
       procesos con mayor prioridad tienen preferencia para ser
       ejecutados.
     - La prioridad puede ser estática (fija) o dinámica (cambia
       durante la ejecución).
     - A veces se emplea un mecanismo de "envejecimiento" para
       aumentar la prioridad de procesos que llevan mucho tiempo
       esperando, evitando que queden bloqueados.
   
   - **Planificación en tiempo real**:
     - Utilizada en sistemas donde las tareas deben completarse dentro
       de plazos específicos, como sistemas de control industrial o de
       aviación.
     - **Tiempo real estricto**: Las tareas deben completarse en un
       momento específico; una falla en el tiempo se considera una
       falla total.
     - **Tiempo real flexible**: Es tolerante a algunos retrasos, pero
       prioriza la finalización de tareas dentro de límites
       razonables.


* Administración de la memoria    


** Política y filosofía de la administración de memoria
La administración de memoria en los sistemas operativos sigue
principios fundamentales que guían su diseño y operación. Entre las
políticas más comunes están:

- **Asignación dinámica vs. estática**: ¿Se asigna memoria en tiempo de
  ejecución o durante la compilación?
- **Swapping**: ¿Cómo se manejan los procesos que no caben en la memoria física?
- **Fragmentación**: Estrategias para minimizar la fragmentación interna y externa.
- **Prioridades**: Asignación de memoria basada en la prioridad de los procesos.

**Ejemplo**: La política de "First Fit" en la asignación de memoria
busca el primer bloque libre suficiente, promoviendo la velocidad pero
pudiendo causar fragmentación.



*** Ejemplos de administración de memoria

**** Asignación dinámica vs. estática
La asignación dinámica y estática se refiere al momento en el que se
reserva la memoria para un programa.

- **Asignación estática**: La memoria se asigna durante la compilación y no cambia en tiempo de ejecución.
  + Ejemplo en C:
    #+BEGIN_SRC c
    nodo arr[1000000]; // Asignación estática
    #+END_SRC
  + Limitación: El tamaño es fijo y debe conocerse antes de la ejecución.
0x21[1°°°°°°°°°°°°°°°°°°°°°°][  ]
- **Asignación dinámica**: La memoria se asigna durante la ejecución según las necesidades del programa.
  + Ejemplo en C:
    #+BEGIN_SRC c
    int *arr = malloc(10 * sizeof(int));
               realloc    // Asignación dinámica
    free(arr); // Liberación de memoria
ox34[°°°°°°][                    ]

   #+END_SRC
  + Ventaja: Permite manejar estructuras cuyo tamaño no es conocido previamente.

*** Swapping
El swapping consiste en mover procesos completos entre la memoria
principal y el disco para liberar espacio.

- **Ejemplo de uso**:
  + Un proceso que no cabe en memoria se guarda temporalmente en el disco.
  + Cuando se necesita, se carga nuevamente en memoria.

- **Diagrama**:
  #+BEGIN_EXAMPLE
  Memoria principal:
  [Proceso A] [Proceso B] [Libre]
  
  Disco:
  [Proceso C]

  Acción: Mover "Proceso C" del disco a la memoria y "Proceso B" al disco.
  #+END_EXAMPLE

- **Ventajas**: Mejora la utilización de memoria.
- **Desventajas**: Incrementa el tiempo de acceso debido a operaciones en disco.

*** Fragmentación
La fragmentación ocurre cuando la memoria se utiliza de manera
ineficiente, dejando pequeños bloques no utilizables.

- **Fragmentación interna**:
  + Bloques asignados son más grandes de lo necesario.
  + Estrategia: Usar bloques más pequeños o ajustar el tamaño según la solicitud.
  + Ejemplo:
    #+BEGIN_EXAMPLE
    Solicitud: 10 KB
    Bloque asignado: 16 KB (6 KB desperdiciados)
    #+END_EXAMPLE

- **Fragmentación externa**:
  + Bloques libres no son contiguos, impidiendo asignaciones grandes.
  + Estrategia: Compactación de memoria o paginación.
  + Ejemplo:
    #+BEGIN_EXAMPLE
    [Libre 10 KB] [Usado 50 KB] [Libre 15 KB]
    Solicitud: 20 KB -> Fallo (No hay bloques contiguos de 20 KB)
    #+END_EXAMPLE

*** Prioridades
La asignación basada en prioridades otorga más recursos a procesos críticos.

- **Ejemplo**:
  + Procesos con alta prioridad reciben memoria inmediatamente.
  + Procesos de baja prioridad esperan.

- **Simulación de asignación**:
  #+BEGIN_EXAMPLE
  Prioridad: 
  - Proceso A: Alta (Se asigna memoria primero)
  - Proceso B: Media
  - Proceso C: Baja (Espera)

  Resultado:
  Memoria asignada a A y B, C espera por liberación.
  #+END_EXAMPLE

  
** Memoria real
La memoria real es la memoria física disponible en un sistema, como la
RAM. Los sistemas operativos deben administrarla eficientemente para
optimizar el rendimiento.

- **Características**:
  - Recursos limitados.
  - Acceso más rápido que la memoria secundaria.
- **Administración**:
  - Dividir en bloques o particiones.
  - Mantener tablas de uso de memoria.

**Ejemplo**: En sistemas monoprogramados, un único proceso utiliza toda
la memoria disponible, mientras que en sistemas multiprogramados se
asignan particiones a múltiples procesos.

**  Organización de memoria virtual
La memoria virtual permite a los programas utilizar más memoria de la
que físicamente está disponible en el sistema. Esto se logra mediante
la abstracción de la memoria secundaria como parte del espacio de
direcciones.

- **Esquema de organización**:
  - **Paginación**: Divide la memoria en bloques de tamaño fijo (páginas).
  - **Segmentación**: Divide la memoria en bloques de tamaño variable
    según las necesidades lógicas.
  - **Paginación con segmentación**: Combinación de ambas técnicas.

**Ventajas**:
- Multiprogramación eficiente.
- Aislamiento de procesos.
- Manejo simplificado de espacios de memoria grandes.

**Ejemplo**:
Un proceso puede acceder a una dirección lógica, que el sistema operativo traduce a una dirección física mediante una tabla de páginas.

** Administración de memoria virtual

Administración de Memoria Virtual
La memoria virtual es un mecanismo que permite a los sistemas
operativos manejar más memoria de la que físicamente está
disponible. Este concepto se basa en la abstracción de la memoria,
permitiendo que los programas trabajen como si tuvieran acceso a un
espacio de memoria continuo y de gran tamaño, independientemente de
las limitaciones físicas.

La administración de memoria virtual es responsable de asignar,
liberar y mantener las estructuras necesarias para garantizar la
operación eficiente de este sistema.

*** Estrategias de Asignación
**** Algoritmos de reemplazo de páginas
Cuando un proceso solicita una página que no está en memoria y no hay espacio disponible, el sistema debe decidir qué página existente se reemplazará. Los algoritmos más comunes son:

- **LRU (Least Recently Used)**:
  - Reemplaza la página que no ha sido utilizada durante más tiempo.
  - Simula el comportamiento real de los procesos, priorizando páginas recientes.
  - **Ventaja**: Buen desempeño en cargas de trabajo típicas.
  - **Desventaja**: Costoso en términos de tiempo y espacio, ya que requiere seguimiento continuo del uso de las páginas.

- **FIFO (First In, First Out)**:
  - Reemplaza la página más antigua en la memoria (la que ingresó primero).
  - **Ventaja**: Simplicidad en la implementación.
  - **Desventaja**: Puede generar resultados ineficientes, como el problema de **Belady** (más fallos de página al aumentar el tamaño de la memoria).

- **Optimal**:
  - Reemplaza la página que no se necesitará por más tiempo en el futuro.
  - **Ventaja**: Ofrece el menor número posible de fallos de página.
  - **Desventaja**: Impracticable en sistemas reales, ya que requiere conocer el acceso futuro.

**** Políticas de carga
Las políticas de carga determinan cuándo se traen las páginas desde el almacenamiento secundario a la memoria principal.

- **Demand Paging**:
  - Solo se cargan las páginas cuando se necesitan, minimizando el uso inicial de memoria.
  - **Ventaja**: Conserva memoria y reduce el tiempo de carga inicial.
  - **Desventaja**: Puede aumentar los fallos de página en el inicio de un proceso.

- **Prefetching**:
  - Se cargan páginas anticipadamente basándose en patrones de acceso previstos.
  - **Ventaja**: Reduce los fallos de página si las predicciones son correctas.
  - **Desventaja**: Puede desperdiciar recursos si las predicciones son incorrectas.

*** Componentes Principales
**** Tabla de Páginas
La tabla de páginas es una estructura de datos clave que relaciona las direcciones lógicas (utilizadas por los programas) con las direcciones físicas (en la memoria).

- **Estructura**:
  - Contiene entradas que mapean páginas lógicas a marcos de memoria física.
  - Cada entrada incluye información sobre si la página está presente en la memoria, bits de protección y un bit de referencia.

- **Desempeño**:
  - Las tablas de páginas grandes pueden consumir mucha memoria.
  - Para optimizar, se usan tablas multinivel o tablas invertidas.

**** TLB (Translation Lookaside Buffer)
El **TLB** es una memoria caché especializada que acelera la traducción de direcciones lógicas a físicas.

- **Funcionamiento**:
  - Almacena un subconjunto de las entradas de la tabla de páginas.
  - Si una dirección lógica se encuentra en el TLB (**hit**), la traducción es rápida.
  - Si no está en el TLB (**miss**), se accede a la tabla de páginas, lo que toma más tiempo.

- **Ventajas**:
  - Reduce significativamente la latencia de acceso a memoria.
  - Mejora el rendimiento en sistemas con altas tasas de traducción de direcciones.

**** Swap
El **swap** es un mecanismo que permite liberar espacio en la memoria física moviendo páginas no activas al disco.

- **Funcionamiento**:
  - Cuando no hay suficiente memoria física, las páginas no utilizadas recientemente se escriben en una porción del disco conocida como **archivo de intercambio**.
  - Si se requiere nuevamente, la página se trae de vuelta a la memoria, reemplazando otra si es necesario.

- **Ventajas**:
  - Permite ejecutar más procesos simultáneamente.
  - Amplía efectivamente el tamaño de la memoria física.

- **Desventajas**:
  - El acceso a disco es mucho más lento que el acceso a memoria física.
  - El uso excesivo de swap puede causar degradación del rendimiento (**thrashing**).

*** Ejemplo: Proceso de Fallo de Página
**** Escenario
Un proceso solicita una página que no está en memoria. Esto genera un **page fault**.

1. **Detección del fallo**:
   - El sistema operativo detecta que la página solicitada no está en memoria.

2. **Selección de la página a reemplazar**:
   - Se utiliza un algoritmo, como LRU, para elegir una página existente en memoria para reemplazar.

3. **Swap in y swap out**:
   - Si la página seleccionada se modificó, se escribe en disco (**swap out**).
   - La página solicitada se lee del disco y se coloca en memoria (**swap in**).

4. **Actualización de estructuras**:
   - La tabla de páginas y, si es aplicable, el TLB se actualizan con la nueva información.

**** Código Representativo (C Pseudocódigo)
#+BEGIN_SRC c
if (page_fault) {
    page_to_replace = select_page_LRU();
    if (page_to_replace.modified) {
        write_to_disk(page_to_replace);
    }
    new_page = read_from_disk(requested_page);
    update_page_table(new_page, memory_frame);
    update_TLB(new_page, memory_frame);
}
#+END_SRC



** Ejercicios

1.  Simulación de particiones fijas:

- Escribe un programa que simule un sistema de administración de
  memoria con particiones fijas.
- Debe permitir al usuario definir el tamaño total de la memoria y las
  particiones.
- Simula la asignación y liberación de procesos a las particiones,
  mostrando cómo se utiliza la memoria.

*** Respuestas

#+BEGIN_SRC C :results output :tangle code/particion.c 
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#define MAX_PARTICIONES 100
#define MAX_PROCESOS 100

typedef struct {
    int tamano;
    int id_de_proceso; // -1 si el proceso no es asignado
} Particion;

void imprime_memoria(Particion Particions[], int numero_de_particiones) {
    printf("\nEstado de la memoria:\n");
    for (int i = 0; i < numero_de_particiones; i++) {
        if (Particions[i].id_de_proceso == -1) {
            printf("Partición %d: %d KB (Libre)\n", i + 1, Particions[i].tamano);
        } else {
            printf("Partición %d: %d KB (Proceso %d)\n", i + 1, Particions[i].tamano, Particions[i].id_de_proceso);
        }
    }
    printf("\n");
}

int main() {
    int memoria_total, numero_de_particiones;
    Particion Particions[MAX_PARTICIONES];

    // Solicitar tamaño total de la memoria
    printf("Ingrese el tamaño total de la memoria (KB): ");
    scanf("%d", &memoria_total);

    // Solicitar número de particiones
    printf("Ingrese el número de particiones: ");
    scanf("%d", &numero_de_particiones);

    if (numero_de_particiones > MAX_PARTICIONES) {
        printf("Número máximo de particiones excedido (%d).\n", MAX_PARTICIONES);
        return 1;
    }

    // Solicitar tamaños de las particiones
    int tamano_total_particion = 0;
    for (int i = 0; i < numero_de_particiones; i++) {
        printf("Ingrese el tamaño de la partición %d (KB): ", i + 1);
        scanf("%d", &Particions[i].tamano);
        Particions[i].id_de_proceso = -1; // Inicialmente, todas están libres
        tamano_total_particion += Particions[i].tamano;
    }

    if (tamano_total_particion > memoria_total) {
        printf("Error: El tamaño total de las particiones excede el tamaño de la memoria.\n");
        return 1;
    }

    int op;
    do {
        printf("\n--- Menú ---\n");
        printf("1. Asignar proceso\n");
        printf("2. Liberar proceso\n");
        printf("3. Mostrar estado de la memoria\n");
        printf("4. Salir\n");
        printf("Seleccione una opción: ");
        scanf("%d", &op);

        switch (op) {
            case 1: {
                int id_de_proceso, tam_proceso;
                printf("Ingrese el ID del proceso: ");
                scanf("%d", &id_de_proceso);
                printf("Ingrese el tamaño del proceso (KB): ");
                scanf("%d", &tam_proceso);

                int asignado = 0;
                for (int i = 0; i < numero_de_particiones; i++) {
                    if (Particions[i].id_de_proceso == -1 && Particions[i].tamano >= tam_proceso) {
                        Particions[i].id_de_proceso = id_de_proceso;
                        asignado = 1;
                        printf("Proceso %d asignado a la partición %d.\n", id_de_proceso, i + 1);
                        break;
                    }
                }
                if (!asignado) {
                    printf("No se encontró una partición disponible para el proceso %d.\n", id_de_proceso);
                }
                break;
            }
            case 2: {
                int id_de_proceso;
                printf("Ingrese el ID del proceso a liberar: ");
                scanf("%d", &id_de_proceso);

                int libre = 0;
                for (int i = 0; i < numero_de_particiones; i++) {
                    if (Particions[i].id_de_proceso == id_de_proceso) {
                        Particions[i].id_de_proceso = -1;
                        libre = 1;
                        printf("Proceso %d liberado de la partición %d.\n", id_de_proceso, i + 1);
                        break;
                    }
                }
                if (!libre) {
                    printf("No se encontró el proceso %d en ninguna partición.\n", id_de_proceso);
                }
                break;
            }
            case 3:
                imprime_memoria(Particions, numero_de_particiones);
                break;
            case 4:
                printf("Saliendo del programa.\n");
                break;
            default:
                printf("Opción no válida.\n");
        }
    } while (op != 4);

    return 0;
}

#+end_src


* Problema de los Filósofos 

Cinco filósofos se sientan alrededor de una mesa y pasan su vida
cenando y pensando. Cada filósofo tiene un plato de fideos y un
tenedor a la izquierda de su plato. Para comer los fideos son
necesarios dos tenedores y cada filósofo sólo puede tomar los que
están a su izquierda y derecha. Si cualquier filósofo toma un tenedor
y el otro está ocupado, se quedará esperando, con el tenedor en la
mano, hasta que pueda tomar el otro tenedor, para luego empezar a
comer.
Si dos filósofos adyacentes intentan tomar el mismo tenedor a una vez,
se produce una condición de carrera: ambos compiten por tomar el mismo
tenedor, y uno de ellos se queda sin comer.
Si todos los filósofos toman el tenedor que está a su derecha al mismo
tiempo, entonces todos se quedarán esperando eternamente, porque
alguien debe liberar el tenedor que les falta. Nadie lo hará porque
todos se encuentran en la misma situación (esperando que alguno deje
sus tenedores). Entonces los filósofos se morirán de hambre. 
El problema consiste en encontrar un algoritmo que permita que los
filósofos nunca se mueran de hambre.




* Administración de entrada/salida
El sistema operativo proporciona una interfaz para la comunicación con
los dispositivos de hardware. Esta sección aborda los conceptos
principales relacionados con la administración de entrada/salida.

** 4.1. Dispositivos y manejadores de dispositivos
- Un **dispositivo** es cualquier hardware que se utiliza para
  transferir datos entre la computadora y el mundo externo o entre
  componentes internos.
  - Ejemplos: teclado, monitor, disco duro, impresora, etc.
- Los **manejadores de dispositivos** son programas que permiten la
  comunicación entre el sistema operativo y los dispositivos de
  hardware.
  - Responsabilidades:
    - Abstracción del hardware: Proveen una interfaz estándar.
    - Control de dispositivos: Activan, desactivan o configuran el hardware.
    - Manejo de errores: Detectan y notifican errores de hardware.

** 4.2. Mecanismos y funciones de los manejadores de dispositivos

- **Mecanismos**: 
  - **Interrupciones**: Señales enviadas por los dispositivos para solicitar atención del CPU.
  - **Polling**: El sistema operativo revisa periódicamente el estado del dispositivo.
  - **DMA (Acceso Directo a Memoria)**: Permite a los dispositivos
    transferir datos directamente a la memoria sin intervención del
    CPU.
- **Funciones**:

  1. **Inicialización**:
     - Configuración del hardware (puertos, registros, etc.).
     - Verificación de disponibilidad del dispositivo.
  2. **Procesamiento de comandos**:
     - Traducción de solicitudes de entrada/salida en comandos
       específicos del hardware.
  3. **Transferencia de datos**:
     - Manejo eficiente de la transferencia entre memoria y dispositivo.
  4. **Finalización**:
     - Limpieza de recursos y notificación al sistema operativo.

** 4.3. Estructuras de datos para manejo de dispositivos
- Las estructuras de datos son fundamentales para organizar y
  gestionar la interacción con dispositivos.
- **Ejemplos comunes**:
  - **Tablas de dispositivos**:
    - Contienen información sobre los dispositivos disponibles en el sistema.
    - Campos: Nombre del dispositivo, tipo, dirección base, etc.
  - **Colas de entrada/salida**:
    - Gestionan las solicitudes pendientes para un dispositivo.
    - Implementan algoritmos de planificación como FCFS (First Come,
      First Serve) o SSTF (Shortest Seek Time First).
  - **Buffers**:
    - Memoria temporal para manejar diferencias en velocidad entre el
      dispositivo y el procesador.
    - Ejemplo: Double buffering para minimizar tiempos de espera.
  - **Tablas de manejadores**:
    - Mapas que asocian operaciones del sistema operativo con las
      funciones del manejador de dispositivos.

** 4.4. Operaciones de entrada/salida
- **Tipos de operaciones**:
  1. **Bloqueantes**:
     - El proceso solicitante se detiene hasta que la operación de E/S se completa.
  2. **No bloqueantes**:
     - El proceso solicitante continúa ejecutándose mientras se realiza la operación de E/S.
  3. **Asíncronas**:
     - El sistema operativo notifica al proceso solicitante cuando la operación de E/S ha terminado.
- **Etapas de la operación de E/S**:
  1. **Solicitud**:
     - El proceso genera una solicitud de E/S al sistema operativo.
  2. **Planificación**:
     - Se decide el orden en que se procesarán las solicitudes (prioridades, tiempo de espera, etc.).
  3. **Transferencia**:
     - Los datos se transfieren entre el dispositivo y la memoria del sistema.
  4. **Notificación**:
     - El sistema operativo informa al proceso solicitante sobre el éxito o el fallo de la operación.

** Ejemplo de código en C para manejo de dispositivos
#+BEGIN_SRC c
#include <stdio.h>
#include <fcntl.h>
#include <unistd.h>
c:
int main() {
    int fd = open("/dev/sda", O_RDONLY); // Abrir el dispositivo en modo de solo lectura
    if (fd < 0) {
        perror("Error al abrir el dispositivo");
        return -1;
    }

    char buffer[512]; // Buffer para leer datos
    ssize_t bytesRead = read(fd, buffer, sizeof(buffer));
    if (bytesRead < 0) {
        perror("Error al leer datos del dispositivo");
        close(fd);
        return -1;
    }

    printf("Se leyeron %ld bytes del dispositivo.\n", bytesRead);
    close(fd);
    return 0;
}
#+END_SRC



* Dispositivos de Entrada y Salida en Linux
** Dispositivos de Entrada
*** Teclado y Mouse
    - `xinput`: Gestiona dispositivos de entrada.
      #+begin_src bash
      xinput list
      #+end_src
    - `evtest`: Monitorea eventos de dispositivos de entrada.
      #+begin_src bash
      sudo evtest
      #+end_src
    - `libinput`: Utilizado para administrar dispositivos en entornos gráficos.
      #+begin_src bash
      sudo libinput list-devices
      #+end_src

*** Pantallas Táctiles
    - `xinput`: Configura parámetros para pantallas táctiles.
      #+begin_src bash
      xinput set-prop <device_id> <property> <value>
      #+end_src

    - `calibrate-touchscreen`: Herramienta para calibrar pantallas táctiles.

** Dispositivos de Salida
*** Pantalla/Monitor
    - `xrandr`: Configura y ajusta pantallas conectadas.
      #+begin_src bash
      xrandr --output <display_name> --mode <resolution>
      #+end_src

    - `arandr`: Interfaz gráfica para `xrandr`.

*** Audio
    - `alsamixer`: Interfaz para controlar el volumen y dispositivos de audio.
      #+begin_src bash
      alsamixer
      #+end_src

    - `pulseaudio`: Controla dispositivos de sonido.
      #+begin_src bash
      pactl list sinks
      #+end_src

    - `pipewire`: Alternativa moderna para gestionar el audio.
      #+begin_src bash
      pw-cli ls Node
      #+end_src

** Dispositivos de Entrada/Salida Generales
*** Almacenamiento
    - `lsblk`: Muestra dispositivos de almacenamiento.
      #+begin_src bash
      lsblk
      #+end_src

    - `mount` y `umount`: Monta y desmonta sistemas de archivos.
      #+begin_src bash
      sudo mount /dev/<device> /mnt/<directory>
      sudo umount /mnt/<directory>
      #+end_src

    - `blkid`: Identifica UUID y etiquetas de particiones.
      #+begin_src bash
      blkid
      #+end_src

*** USB
    - `lsusb`: Lista dispositivos USB conectados.
      #+begin_src bash
      lsusb
      #+end_src

    - `usb-devices`: Muestra detalles de los dispositivos USB.
      #+begin_src bash
      usb-devices
      #+end_src

*** Red
    - `ip link`: Lista interfaces de red.
      #+begin_src bash
      ip link show
      #+end_src

    - `nmcli`: Administra conexiones de red.
      #+begin_src bash
      nmcli device show
      #+end_src



* Actividades

El objetivo de estas actividades es fortalecer tu comprensión de dos
áreas fundamentales en sistemas operativos: la administración de
memoria y la administración de entrada/salida (E/S). Estos conceptos
son esenciales para entender cómo un sistema operativo gestiona los
recursos de hardware y software para garantizar el funcionamiento
eficiente de un equipo de cómputo.


** ¿Qué se espera de ti?
1. **Lectura y análisis crítico**:
   - Antes de comenzar las actividades, revisa los temas relacionados
     en tu material de estudio o en recursos confiables. Asegúrate de
     comprender los conceptos clave, como memoria virtual, paginación,
     dispositivos de bloque y planificación de discos.
   - Reflexiona sobre cómo estos conceptos son aplicados en sistemas
     operativos modernos como Linux o Windows.

2. **Desarrollo práctico**:
   - Implementarás programas en lenguajes como C o Python para simular
     y profundizar en los mecanismos estudiados. Esto incluye la
     creación de algoritmos de administración de memoria y simuladores
     de entrada/salida.
   - Al realizar estas tareas, te familiarizarás con técnicas de
     programación orientadas a sistemas, como el manejo de memoria
     dinámica, la gestión de interrupciones y la planificación de
     recursos.

3. **Resolución de problemas**:
   - Las actividades incluyen preguntas teóricas y prácticas diseñadas
     para retarte a analizar problemas reales y proponer soluciones
     innovadoras.
   - Se espera que simules entornos de sistemas operativos y explores
     cómo interactúan sus componentes clave.








** Administración de Memoria
*** 3.1 Política y filosofía
1. ¿Cuál es la diferencia entre fragmentación interna y externa? Explica cómo cada una afecta el rendimiento de la memoria.
2. Investiga y explica las políticas de reemplazo de páginas en sistemas operativos. ¿Cuál consideras más eficiente y por qué?

*** 3.2 Memoria real
3. Escribe un programa en C o Python que simule la administración de memoria mediante particiones fijas.
4. Diseña un algoritmo para calcular qué procesos pueden ser asignados a un sistema con memoria real limitada utilizando el algoritmo de "primera cabida".

*** 3.3 Organización de memoria virtual
5. Investiga y explica el concepto de "paginación" y "segmentación". ¿Cuáles son las ventajas y desventajas de cada técnica?
6. Escribe un programa que simule una tabla de páginas para procesos con acceso aleatorio a memoria virtual.

*** 3.4 Administración de memoria virtual
7. Escribe un código que implemente el algoritmo de reemplazo de página "Least Recently Used" (LRU).
8. Diseña un diagrama que represente el proceso de traducción de direcciones virtuales a físicas en un sistema con memoria virtual.

*** Integración
9. Analiza un sistema operativo moderno (por ejemplo, Linux o Windows) e identifica cómo administra la memoria virtual.
10. Realiza una simulación en cualquier lenguaje de programación que emule el swapping de procesos en memoria virtual.

** Administración de Entrada/Salida
*** 4.1 Dispositivos y manejadores de dispositivos
1. Explica la diferencia entre dispositivos de bloque y dispositivos de carácter. Da un ejemplo de cada uno.
2. Diseña un programa que implemente un manejador de dispositivos sencillo para un dispositivo virtual de entrada.

*** 4.2 Mecanismos y funciones de los manejadores de dispositivos
3. Investiga qué es la interrupción por E/S y cómo la administra el sistema operativo. Escribe un ejemplo en pseudocódigo para simular este proceso.
4. Escribe un programa que utilice el manejo de interrupciones en un sistema básico de simulación.

*** 4.3 Estructuras de datos para manejo de dispositivos
5. Investiga y explica qué es una cola de E/S. Diseña una simulación de una cola con prioridad.
6. Escribe un programa que simule las operaciones de un manejador de dispositivos utilizando una tabla de estructuras.

*** 4.4 Operaciones de Entrada/Salida
7. Diseña un flujo que describa el proceso de lectura de un archivo desde un disco magnético. Acompáñalo con un programa básico que simule el proceso.
8. Implementa un programa en Python, C o java  que realice operaciones de entrada/salida asíncronas usando archivos.

*** Integración
9. Escribe un programa que implemente el algoritmo de planificación de discos "Elevator (SCAN)".
10. Diseña un sistema que maneje múltiples dispositivos simulados (disco duro, impresora, teclado) y muestra cómo se realiza la comunicación entre ellos.

*** Avanzados
11. Explica cómo los sistemas operativos modernos optimizan las operaciones de entrada/salida con el uso de memoria caché.







* Actividades: Dispositivos de entrada y salida en Linux

** Introducción
   En este ejercicio, aprenderá a listar,
   verificar y analizar los dispositivos de entrada y salida en
   Linux. Usarán comandos básicos y herramientas comunes disponibles
   en cualquier distribución.

** Actividad 1: Listar dispositivos conectados
*** Objetivo
Conocer los dispositivos de entrada y salida conectados al sistema.
*** Instrucciones
    1. Abra una terminal en su entorno Linux.
    2. Ejecute los siguientes comandos y anote sus observaciones:
       - `lsblk`: Enumera los dispositivos de bloque.
       - `lsusb`: Lista los dispositivos conectados a los puertos USB.
       - `lspci`: Muestra los dispositivos conectados al bus PCI.
       - `dmesg | grep usb`: Muestra los mensajes del kernel relacionados con dispositivos USB.
    3. Conteste:
       - ¿Qué tipos de dispositivos se muestran en la salida de `lsblk`?
       - ¿Cuál es la diferencia entre `lsusb` y `lspci`?
       - ¿Qué información adicional proporciona `dmesg | grep usb`?


	
** Actividad 2: Verificar dispositivos de almacenamiento
*** Objetivo
    Aprender cómo identificar discos duros, particiones y su
    configuración.
*** Instrucciones
    1. Use el comando `fdisk -l` para listar todos los discos y
       particiones.
    2. Utilice `blkid` para ver los identificadores UUID y los tipos
       de sistema de archivos.
    3. Use `df -h` para listar los dispositivos montados y su espacio
       disponible.
    4. Conteste:
       - ¿Qué dispositivos de almacenamiento están conectados a su
         sistema?
       - ¿Qué particiones están montadas actualmente?
       - ¿Qué tipo de sistemas de archivos se usan en las particiones?

** Actividad 3: Explorar dispositivos de entrada
*** Objetivo
    Identificar dispositivos como teclados, ratones y cámaras.
*** Instrucciones
    1. Ejecute `cat /proc/bus/input/devices` para listar los
       dispositivos de entrada.
    2. Use `evtest` para monitorear eventos de dispositivos de entrada (requiere permisos de superusuario).
    3. Investigue los siguientes dispositivos:
       - Teclado
       - Mouse
       - Controladores USB adicionales
    4. Conteste:
       - ¿Qué eventos genera cada dispositivo al interactuar con
         ellos?
       - ¿Cómo se identifican los dispositivos en
         `/proc/bus/input/devices`?

** Actividad 4: Examinar dispositivos de salida
*** Objetivo
    Entender cómo identificar dispositivos de salida como monitores y tarjetas de sonido.
*** Instrucciones
    1. Use `xrandr` para listar las pantallas conectadas y sus resoluciones.
    2. Ejecute `aplay -l` para listar las tarjetas de sonido disponibles.
    3. Use `lsof /dev/snd/*` para ver qué procesos están utilizando la tarjeta de sonido.
    4. Conteste:
       - ¿Qué salidas de video están disponibles en su sistema?
       - ¿Qué dispositivos de sonido se detectaron?
       - ¿Qué procesos están usando la tarjeta de sonido?

** Actividad 5: Crear un script de resumen
*** Objetivo
    Automatizar la recopilación de información de dispositivos de entrada y salida.
*** Instrucciones
    1. Cree un archivo llamado `dispositivos.sh` y agregue el siguiente contenido:
       ```bash
       #!/bin/bash
       echo "Dispositivos de bloque:"
       lsblk
       echo "Dispositivos USB:"
       lsusb
       echo "Dispositivos PCI:"
       lspci
       echo "Dispositivos de entrada:"
       cat /proc/bus/input/devices
       echo "Salidas de video:"
       xrandr
       echo "Tarjetas de sonido:"
       aplay -l
       ```
    2. Ejecute el script usando `bash dispositivos.sh`.
    3. Modifique el script para guardar la salida en un archivo llamado `resumen_dispositivos.txt`.
    4. Conteste:
       - ¿Qué ventajas tiene usar un script para recopilar esta información?
       - ¿Qué cambios realizaría para personalizar el script?

** Actividad 6: Reflexión y discusión
*** Objetivo
    Analizar la importancia del manejo de dispositivos en sistemas Linux.
*** Instrucciones
    1. Reflexione sobre lo aprendido y discuta en equipo:
       - ¿Qué comando encontró más útil y por qué?
       - ¿Qué tan importante es conocer los dispositivos conectados al sistema?
       - ¿Cómo podrían estos conocimientos aplicarse en la administración de sistemas?


	


*  Comandos de Entrada y Salida, Discos y Archivos
** Ejercicio 1: Montar y Desmontar Discos
   - **Objetivo:** Aprender a montar y desmontar un dispositivo externo.
   1. Inserta una memoria USB en el sistema.
   2. Encuentra el dispositivo usando el comando:
      #+BEGIN_SRC bash
      lsblk
      #+END_SRC
      o
      #+BEGIN_SRC bash
      fdisk -l
      #+END_SRC
   3. Monta la memoria USB en un directorio, por ejemplo, `/mnt/usb`:
      #+BEGIN_SRC bash
      sudo mount /dev/sdX1 /mnt/usb
      #+END_SRC
   4. Verifica que esté montado correctamente:
      #+BEGIN_SRC bash
      df -h
      #+END_SRC
   5. Copia un archivo desde tu directorio personal al dispositivo USB:
      #+BEGIN_SRC bash
      cp archivo.txt /mnt/usb/
      #+END_SRC
   6. Desmonta la memoria USB:
      #+BEGIN_SRC bash
      sudo umount /mnt/usb
      #+END_SRC

** Ejercicio 2: Redirección de Entrada y Salida
   - **Objetivo:** Usar redirección para guardar la salida de comandos en archivos.
   1. Lista los archivos de tu directorio actual y guarda el resultado en un archivo `listado.txt`:
      #+BEGIN_SRC bash
      ls -l > listado.txt
      #+END_SRC
   2. Muestra el contenido del archivo en la terminal:
      #+BEGIN_SRC bash
      cat listado.txt
      #+END_SRC
   3. Añade la fecha actual al final del archivo:
      #+BEGIN_SRC bash
      date >> listado.txt
      #+END_SRC
   4. Muestra todo el contenido del archivo nuevamente:
      #+BEGIN_SRC bash
      cat listado.txt
      #+END_SRC

** Ejercicio 3: Copiar y Mover Archivos
   - **Objetivo:** Practicar copiar y mover archivos y directorios.
   1. Crea un archivo de texto llamado `archivo1.txt`:
      #+BEGIN_SRC bash
      echo "Este es un archivo de prueba" > archivo1.txt
      #+END_SRC
   2. Copia este archivo a otro directorio, por ejemplo, `/tmp`:
      #+BEGIN_SRC bash
      cp archivo1.txt /tmp/
      #+END_SRC
   3. Renombra el archivo copiado a `archivo2.txt` en `/tmp`:
      #+BEGIN_SRC bash
      mv /tmp/archivo1.txt /tmp/archivo2.txt
      #+END_SRC
   4. Mueve el archivo `archivo2.txt` de vuelta a tu directorio actual:
      #+BEGIN_SRC bash
      mv /tmp/archivo2.txt .
      #+END_SRC

** Ejercicio 4: Comprimir y Descomprimir Archivos
   - **Objetivo:** Aprender a trabajar con compresión de archivos.
   1. Crea un directorio llamado `backup` y copia algunos archivos en él.
   2. Comprime el directorio `backup` en un archivo `.tar.gz`:
      #+BEGIN_SRC bash
      tar -czvf backup.tar.gz backup/
      #+END_SRC
   3. Borra el directorio original y extrae el contenido del archivo comprimido:
      #+BEGIN_SRC bash
      tar -xzvf backup.tar.gz
      #+END_SRC

** Ejercicio 5: Permisos y Propiedades de Archivos
   - **Objetivo:** Aprender a modificar permisos y propietarios de archivos.
   1. Crea un archivo llamado `privado.txt`:
      #+BEGIN_SRC bash
      touch privado.txt
      #+END_SRC
   2. Cambia los permisos del archivo para que solo el propietario pueda leer y escribir:
      #+BEGIN_SRC bash
      chmod 600 privado.txt
      #+END_SRC
   3. Cambia el propietario del archivo a otro usuario (si tienes privilegios):
      #+BEGIN_SRC bash
      sudo chown usuario privado.txt
      #+END_SRC

** Ejercicio 6: Exploración de Dispositivos
   - **Objetivo:** Identificar discos y particiones en el sistema.
   1. Usa `lsblk` para listar los discos y particiones:
      #+BEGIN_SRC bash
      lsblk
      #+END_SRC
   2. Usa `du -sh` para ver el tamaño del contenido en un directorio de tu elección:
      #+BEGIN_SRC bash
      du -sh /ruta/directorio
      #+END_SRC
   3. Verifica el uso de disco con `df -h`:
      #+BEGIN_SRC bash
      df -h
      #+END_SRC

** Ejercicio 7: Crear y Formatear Particiones
   - **Objetivo:** Crear y formatear una nueva partición (Usar disco de práctica o máquina virtual).
   1. Identifica un disco no particionado:
      #+BEGIN_SRC bash
      sudo fdisk -l
      #+END_SRC
   2. Usa `fdisk` para crear una nueva partición:
      #+BEGIN_SRC bash
      sudo fdisk /dev/sdX
      #+END_SRC
   3. Formatea la partición como `ext4`:
      #+BEGIN_SRC bash
      sudo mkfs.ext4 /dev/sdX1
      #+END_SRC
   4. Monta la partición en un directorio y prueba escribiendo archivos en ella:
      #+BEGIN_SRC bash
      sudo mount /dev/sdX1 /mnt/nueva_particion
      echo "Prueba de escritura" > /mnt/nueva_particion/test.txt
      #+END_SRC

	
